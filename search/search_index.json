{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Pyxations Documentation","text":"<p>Welcome to the official documentation for Pyxations, a Python package for handling and analyzing eye-tracking data.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>BIDS Conversion: Convert your dataset to BIDS format, automatically organizing files according to BIDS standards.</li> <li>EDF to ASCII Conversion: Convert EDF files to ASCII format using <code>edf2asc</code>, a tool provided by EyeLink.</li> <li>EDF Parsing: Parse EDF files generated by the EyeLink system to extract various data structures, including header information, messages, calibration data, events, and raw samples.</li> <li>Trial Segmentation: Segment continuous eye-tracking data into trials using flexible methods, including start/end messages, fixed durations, or explicit start/end times.</li> <li>Derivative Computation: Compute derivatives for a dataset by parsing EDF files and storing the results in an organized manner.</li> <li>Processing Derivatives: Process the derivatives by performing eye movement detection, classifying saccades, splitting them into trials, and visualizing the results.</li> <li>Eye Movement Detection: Detect fixations and saccades using multiple algorithms like REMoDNaV, Engbert\u2013Kliegl, among others.</li> <li>Saccades Direction Classification: Classify saccades based on their start and end coordinates into four primary directions: right, left, up, and down.</li> </ul>"},{"location":"api_reference/","title":"API Reference","text":"<p>This page gives an overview of all public pyxations objects, functions and methods. </p>"},{"location":"api_reference/#pre_processing","title":"pre_processing","text":""},{"location":"api_reference/#pyxations.pre_processing.PreProcessing","title":"<code>PreProcessing</code>","text":"<p>Pyxations preprocessing: trial segmentation, quality flags, and saccade direction. All mutating functions are safe (copy-aware) and validate required columns.</p> <p>Tables (pd.DataFrame) expected:     samples:   typically contains 'tSample' (ms), gaze columns (e.g., 'LX','LY','RX','RY' or 'X','Y')     fixations: typically contains 'tStart','tEnd' and optional 'xAvg','yAvg'     saccades:  typically contains 'tStart','tEnd','xStart','yStart','xEnd','yEnd'     blinks:    typically contains 'tStart','tEnd' (optional)     user_messages: must contain 'timestamp','message'</p> <p>New columns created:     - All tables after trialing: 'phase', 'trial_number', 'trial_label' (optional)     - samples/fixations/saccades: 'bad' (bool) after bad_samples()     - saccades: 'deg' (float degrees), 'dir' (str) after saccades_direction()</p> Source code in <code>pyxations/pre_processing.py</code> <pre><code>class PreProcessing:\n    \"\"\"\n    Pyxations preprocessing: trial segmentation, quality flags, and saccade direction.\n    All mutating functions are safe (copy-aware) and validate required columns.\n\n    Tables (pd.DataFrame) expected:\n        samples:   typically contains 'tSample' (ms), gaze columns (e.g., 'LX','LY','RX','RY' or 'X','Y')\n        fixations: typically contains 'tStart','tEnd' and optional 'xAvg','yAvg'\n        saccades:  typically contains 'tStart','tEnd','xStart','yStart','xEnd','yEnd'\n        blinks:    typically contains 'tStart','tEnd' (optional)\n        user_messages: must contain 'timestamp','message'\n\n    New columns created:\n        - All tables after trialing: 'phase', 'trial_number', 'trial_label' (optional)\n        - samples/fixations/saccades: 'bad' (bool) after bad_samples()\n        - saccades: 'deg' (float degrees), 'dir' (str) after saccades_direction()\n    \"\"\"\n\n    VERSION = \"0.2.0\"\n\n    def __init__(\n        self,\n        samples: pd.DataFrame,\n        fixations: pd.DataFrame,\n        saccades: pd.DataFrame,\n        blinks: pd.DataFrame,\n        user_messages: pd.DataFrame,\n        session_path: PathLike,\n        metadata: Optional[SessionMetadata] = None,\n    ):\n        self.samples = samples.copy()\n        self.fixations = fixations.copy()\n        self.saccades = saccades.copy()\n        self.blinks = blinks.copy()\n        self.user_messages = user_messages.copy()\n        self.session_path = Path(session_path)\n        self.metadata = metadata or SessionMetadata()\n\n        # Normalize dtypes where possible (strings for messages)\n        if \"message\" in self.user_messages.columns:\n            self.user_messages[\"message\"] = self.user_messages[\"message\"].astype(str)\n\n    # ------------------------------- Utilities ------------------------------- #\n\n    @staticmethod\n    def _require_columns(\n        df: pd.DataFrame, cols: Sequence[str], context: str\n    ) -&gt; None:\n        missing = [c for c in cols if c not in df.columns]\n        if missing:\n            raise ValueError(\n                f\"[{context}] Missing required columns: {missing}. \"\n                f\"Available: {list(df.columns)}\"\n            )\n\n    @staticmethod\n    def _assert_nonoverlap(starts: Sequence[int], ends: Sequence[int], key: str, session: Path) -&gt; None:\n        if len(starts) != len(ends):\n            raise ValueError(\n                f\"[{key}] start_times and end_times must have the same length, \"\n                f\"got {len(starts)} vs {len(ends)} in session: {session}\"\n            )\n        for i, (s, e) in enumerate(zip(starts, ends)):\n            if not (s &lt; e):\n                raise ValueError(\n                    f\"[{key}] Non-positive interval at trial {i}: start={s}, end={e} \"\n                    f\"in session: {session}\"\n                )\n            if i &lt; len(starts) - 1:\n                if e &gt; starts[i + 1]:\n                    raise ValueError(\n                        f\"[{key}] Overlapping trials {i}\u2013{i+1}: end[i]={e} &gt; start[i+1]={starts[i+1]} \"\n                        f\"in session: {session}\"\n                    )\n\n    @staticmethod\n    def _ensure_columns_exist(df: pd.DataFrame, cols: Sequence[str]) -&gt; List[str]:\n        \"\"\"Return the subset of 'cols' that actually exist in df.\"\"\"\n        return [c for c in cols if c in df.columns]\n\n    def _save_json_sidecar(self, obj: dict, filename: str) -&gt; None:\n        outdir = self.session_path\n        outdir.mkdir(parents=True, exist_ok=True)\n        with open(outdir / filename, \"w\", encoding=\"utf-8\") as f:\n            json.dump(obj, f, indent=2, ensure_ascii=False)\n\n    # ---------------------------- Public API: Meta ---------------------------- #\n\n    def set_metadata(\n        self,\n        coords_unit: Optional[str] = None,\n        time_unit: Optional[str] = None,\n        pupil_unit: Optional[str] = None,\n        screen_width: Optional[int] = None,\n        screen_height: Optional[int] = None,\n        **extra,\n    ) -&gt; None:\n        \"\"\"Update session-level metadata used in bounds checks and documentation.\"\"\"\n        if coords_unit is not None:\n            self.metadata.coords_unit = coords_unit\n        if time_unit is not None:\n            self.metadata.time_unit = time_unit\n        if pupil_unit is not None:\n            self.metadata.pupil_unit = pupil_unit\n        if screen_width is not None:\n            self.metadata.screen_width = screen_width\n        if screen_height is not None:\n            self.metadata.screen_height = screen_height\n        self.metadata.extra.update(extra)\n\n    def save_metadata(self, filename: str = \"metadata.json\") -&gt; None:\n        \"\"\"Persist metadata next to derivatives for reproducibility.\"\"\"\n        self._save_json_sidecar(self.metadata.to_dict(), filename)\n\n    # ----------------------- Public API: Message Parsing ---------------------- #\n\n    def get_timestamps_from_messages(\n        self,\n        messages_dict: Dict[str, List[str]],\n        *,\n        case_insensitive: bool = True,\n        use_regex: bool = True,\n        return_match_token: bool = False,\n    ) -&gt; Dict[str, List[int]]:\n        \"\"\"\n        Extract ordered timestamps per phase by matching message substrings/patterns.\n\n        Parameters\n        ----------\n        messages_dict : dict\n            e.g., {'trial': ['TRIAL_START', 'BEGIN_TRIAL'], 'stim': ['STIM_ONSET']}\n        case_insensitive : bool\n            If True, ignore case during matching.\n        use_regex : bool\n            If True, treat entries as regex patterns joined by '|'; otherwise escape literals.\n        return_match_token : bool\n            If True, also creates/updates a 'matched_token' column with the first matched pattern.\n\n        Returns\n        -------\n        Dict[str, List[int]]\n            Ordered timestamps in ms for each key.\n        \"\"\"\n        df = self.user_messages\n        self._require_columns(df, [\"timestamp\", \"message\"], \"get_timestamps_from_messages\")\n\n        timestamps_dict: Dict[str, List[int]] = {}\n        flags = re.I if case_insensitive else 0\n\n        # Prepare an optional matched_token column for traceability\n        if return_match_token and \"matched_token\" not in df.columns:\n            df = df.copy()\n            df[\"matched_token\"] = pd.Series([None] * len(df), index=df.index)\n\n        for key, tokens in messages_dict.items():\n            if not tokens:\n                raise ValueError(f\"[{key}] Empty token list passed to get_timestamps_from_messages.\")\n            parts = tokens if use_regex else [re.escape(t) for t in tokens]\n            pat = re.compile(\"|\".join(parts), flags=flags)\n\n            hits = df[df[\"message\"].str.contains(pat, regex=True, na=False)].copy()\n            hits.sort_values(by=\"timestamp\", inplace=True)\n\n            if return_match_token and not hits.empty:\n                # record which token matched first for each hit\n                def _which(m: str) -&gt; Optional[str]:\n                    for t in tokens:\n                        if (re.search(t, m, flags=flags) if use_regex else re.search(re.escape(t), m, flags=flags)):\n                            return t\n                    return None\n\n                hits[\"matched_token\"] = hits[\"message\"].apply(_which)\n                # write back those rows (optional traceability)\n                df.loc[hits.index, \"matched_token\"] = hits[\"matched_token\"]\n\n            stamps = hits[\"timestamp\"].astype(int).tolist()\n            if len(stamps) == 0:\n                raise ValueError(\n                    f\"[{key}] No timestamps found for messages {tokens} \"\n                    f\"in session: {self.session_path}\"\n                )\n            timestamps_dict[key] = stamps\n\n        # Persist updated matched_token if requested\n        if return_match_token:\n            self.user_messages = df\n\n        return timestamps_dict\n\n    # ---------------------- Public API: Trial Segmentation -------------------- #\n\n    def split_all_into_trials(\n        self,\n        start_times: Dict[str, List[int]],\n        end_times: Dict[str, List[int]],\n        trial_labels: Optional[Dict[str, List[str]]] = None,\n        *,\n        allow_open_last: bool = True,\n        require_nonoverlap: bool = True,\n    ) -&gt; None:\n        \"\"\"Segment samples/fixations/saccades/blinks using explicit times.\"\"\"\n        for df in (self.samples, self.fixations, self.saccades, self.blinks):\n            self._split_into_trials_df(\n                df, start_times, end_times, trial_labels,\n                allow_open_last=allow_open_last,\n                require_nonoverlap=require_nonoverlap,\n            )\n\n    def split_all_into_trials_by_msgs(\n        self,\n        start_msgs: Dict[str, List[str]],\n        end_msgs: Dict[str, List[str]],\n        trial_labels: Optional[Dict[str, List[str]]] = None,\n        **msg_kwargs,\n    ) -&gt; None:\n        \"\"\"Segment tables using start and end message patterns.\"\"\"\n        starts = self.get_timestamps_from_messages(start_msgs, **msg_kwargs)\n        ends = self.get_timestamps_from_messages(end_msgs, **msg_kwargs)\n        self.split_all_into_trials(starts, ends, trial_labels)\n\n    def split_all_into_trials_by_durations(\n        self,\n        start_msgs: Dict[str, List[str]],\n        durations: Dict[str, List[int]],\n        trial_labels: Optional[Dict[str, List[str]]] = None,\n        **msg_kwargs,\n    ) -&gt; None:\n        \"\"\"Segment using start message patterns and per-trial durations (ms).\"\"\"\n        starts = self.get_timestamps_from_messages(start_msgs, **msg_kwargs)\n        end_times: Dict[str, List[int]] = {}\n        for key, durs in durations.items():\n            s = starts.get(key, [])\n            if len(durs) &lt; len(s):\n                raise ValueError(\n                    f\"[{key}] Provided {len(durs)} durations but found {len(s)} start times \"\n                    f\"in session: {self.session_path}\"\n                )\n            end_times[key] = [st + du for st, du in zip(s, durs)]\n        self.split_all_into_trials(starts, end_times, trial_labels)\n\n    def _split_into_trials_df(\n        self,\n        data: pd.DataFrame,\n        start_times: Dict[str, List[int]],\n        end_times: Dict[str, List[int]],\n        trial_labels: Optional[Dict[str, List[str]]] = None,\n        *,\n        allow_open_last: bool = True,\n        require_nonoverlap: bool = True,\n    ) -&gt; None:\n        \"\"\"\n        Core segmentation for a single table. Works with 'tSample' OR ('tStart','tEnd').\n        Adds 'phase', 'trial_number', 'trial_label'.\n        \"\"\"\n        if data is self.samples:\n            time_mode = \"sample\"\n            self._require_columns(data, [\"tSample\"], \"split_into_trials(samples)\")\n        else:\n            # events (fixations/saccades/blinks)\n            time_mode = \"event\"\n            self._require_columns(data, [\"tStart\", \"tEnd\"], \"split_into_trials(events)\")\n\n        df = data.copy()\n        # Initialize columns deterministically\n        df[\"phase\"] = \"\"\n        df[\"trial_number\"] = -1\n        df[\"trial_label\"] = \"\"\n\n        for key in start_times.keys():\n            start_list = list(start_times[key])\n            end_list = list(end_times[key])\n\n            # Discard starts after last end (common partial last-trial artifact)\n            if allow_open_last and end_list:\n                last_end = end_list[-1]\n                start_list = [st for st in start_list if st &lt; last_end]\n\n            # Sanity checks\n            if require_nonoverlap:\n                self._assert_nonoverlap(start_list, end_list, key, self.session_path)\n            elif len(start_list) != len(end_list):\n                raise ValueError(\n                    f\"[{key}] start_times and end_times length mismatch: {len(start_list)} vs {len(end_list)} \"\n                    f\"in session: {self.session_path}\"\n                )\n\n            labels = trial_labels.get(key) if (trial_labels and key in trial_labels) else None\n            if labels is not None and len(labels) != len(start_list):\n                raise ValueError(\n                    f\"[{key}] Computed {len(start_list)} trials but got {len(labels)} trial labels \"\n                    f\"in session: {self.session_path}\"\n                )\n\n            # Apply segmentation\n            if time_mode == \"sample\":\n                t = df[\"tSample\"].values\n                for i, (st, en) in enumerate(zip(start_list, end_list)):\n                    mask = (t &gt;= st) &amp; (t &lt;= en)\n                    if not np.any(mask):\n                        continue\n                    df.loc[mask, \"trial_number\"] = i\n                    df.loc[mask, \"phase\"] = str(key)\n                    if labels is not None:\n                        df.loc[mask, \"trial_label\"] = labels[i]\n            else:\n                t0 = df[\"tStart\"].values\n                t1 = df[\"tEnd\"].values\n                for i, (st, en) in enumerate(zip(start_list, end_list)):\n                    mask = (t0 &gt;= st) &amp; (t1 &lt;= en)\n                    if not np.any(mask):\n                        continue\n                    df.loc[mask, \"trial_number\"] = i\n                    df.loc[mask, \"phase\"] = str(key)\n                    if labels is not None:\n                        df.loc[mask, \"trial_label\"] = labels[i]\n\n        # Commit\n        if data is self.samples:\n            self.samples = df\n        elif data is self.fixations:\n            self.fixations = df\n        elif data is self.saccades:\n            self.saccades = df\n        elif data is self.blinks:\n            self.blinks = df\n\n    # ------------------------- Public API: QC / Flags ------------------------- #\n\n    def bad_samples(\n        self,\n        screen_height: Optional[int] = None,\n        screen_width: Optional[int] = None,\n        *,\n        mark_nan_as_bad: bool = True,\n        inclusive_bounds: bool = True,\n    ) -&gt; None:\n        \"\"\"\n        Mark rows as 'bad' if any available coordinate falls outside screen bounds.\n        Applies to samples, fixations, saccades. (Blinks unaffected.)\n\n        If width/height not provided, will use metadata.screen_* if available.\n        \"\"\"\n        H = screen_height if screen_height is not None else self.metadata.screen_height\n        W = screen_width if screen_width is not None else self.metadata.screen_width\n        if H is None or W is None:\n            raise ValueError(\n                \"bad_samples requires screen_height and screen_width (either passed \"\n                \"or set via set_metadata()).\"\n            )\n\n        def _mark(df: pd.DataFrame) -&gt; pd.DataFrame:\n            d = df.copy()\n\n            # Gather candidate coordinate columns if present\n            coord_cols = self._ensure_columns_exist(\n                d,\n                [\n                    \"LX\", \"LY\", \"RX\", \"RY\", \"X\", \"Y\",\n                    \"xStart\", \"xEnd\", \"yStart\", \"yEnd\", \"xAvg\", \"yAvg\",\n                ],\n            )\n            if not coord_cols:\n                # If no coords present, default to 'not bad'\n                if \"bad\" not in d.columns:\n                    d[\"bad\"] = False\n                return d\n\n            xcols = [c for c in coord_cols if c.lower().startswith(\"x\")]\n            ycols = [c for c in coord_cols if c.lower().startswith(\"y\")]\n\n            # Validity masks for each axis\n            if inclusive_bounds:\n                valid_w = np.logical_and.reduce([d[c].ge(0) &amp; d[c].le(W) for c in xcols]) if xcols else True\n                valid_h = np.logical_and.reduce([d[c].ge(0) &amp; d[c].le(H) for c in ycols]) if ycols else True\n            else:\n                valid_w = np.logical_and.reduce([d[c].gt(0) &amp; d[c].lt(W) for c in xcols]) if xcols else True\n                valid_h = np.logical_and.reduce([d[c].gt(0) &amp; d[c].lt(H) for c in ycols]) if ycols else True\n\n            bad = ~(valid_w &amp; valid_h)\n            if mark_nan_as_bad:\n                bad |= d[coord_cols].isna().any(axis=1)\n\n            d[\"bad\"] = bad.values\n            return d\n\n        self.samples = _mark(self.samples)\n        self.fixations = _mark(self.fixations)\n        self.saccades = _mark(self.saccades)\n\n    # ---------------------- Public API: Saccade Direction --------------------- #\n\n    def saccades_direction(self, tol_deg: float = 15.0) -&gt; None:\n        \"\"\"\n        Compute saccade angle (deg) and cardinal direction with tolerance bands.\n\n        Parameters\n        ----------\n        tol_deg : float\n            Half-width of the acceptance band around 0\u00b0, \u00b190\u00b0, and \u00b1180\u00b0\n            for classifying right/left/up/down.\n        \"\"\"\n        df = self.saccades.copy()\n        self._require_columns(\n            df, [\"xStart\", \"xEnd\", \"yStart\", \"yEnd\"], \"saccades_direction\"\n        )\n\n        x_dif = df[\"xEnd\"].astype(float) - df[\"xStart\"].astype(float)\n        y_dif = df[\"yEnd\"].astype(float) - df[\"yStart\"].astype(float)\n        deg = np.degrees(np.arctan2(y_dif.to_numpy(), x_dif.to_numpy()))\n        df[\"deg\"] = deg.astype(float)\n\n        # Tolerant direction bins\n        right = (-tol_deg &lt; df[\"deg\"]) &amp; (df[\"deg\"] &lt; tol_deg)\n        left = (df[\"deg\"] &gt; 180 - tol_deg) | (df[\"deg\"] &lt; -180 + tol_deg)\n        down = ((90 - tol_deg) &lt; df[\"deg\"]) &amp; (df[\"deg\"] &lt; (90 + tol_deg))\n        up = ((-90 - tol_deg) &lt; df[\"deg\"]) &amp; (df[\"deg\"] &lt; (-90 + tol_deg))\n\n        df[\"dir\"] = \"\"\n        df.loc[right, \"dir\"] = \"right\"\n        df.loc[left, \"dir\"] = \"left\"\n        df.loc[down, \"dir\"] = \"down\"\n        df.loc[up, \"dir\"] = \"up\"\n\n        self.saccades = df\n\n    # -------------------------- Public API: Orchestrator ---------------------- #\n\n    def process(\n        self,\n        functions_and_params: Dict[str, Dict],\n        *,\n        log_recipe: bool = True,\n        recipe_filename: str = \"preprocessing_recipe.json\",\n        provenance_filename: str = \"preprocessing_provenance.json\",\n    ) -&gt; None:\n        \"\"\"\n        Run a declarative preprocessing recipe, e.g.:\n            pp.process({\n                \"split_all_into_trials_by_msgs\": {\n                    \"start_msgs\": {\"trial\": [\"TRIAL_START\"]},\n                    \"end_msgs\": {\"trial\": [\"TRIAL_END\"]},\n                },\n                \"bad_samples\": {\"screen_height\": 1080, \"screen_width\": 1920},\n                \"saccades_direction\": {\"tol_deg\": 15},\n            })\n\n        Unknown function names raise a helpful error.\n        \"\"\"\n        # Optional: save the declared recipe for exact reproducibility\n        if log_recipe:\n            recipe_obj = {\n                \"declared_recipe\": functions_and_params,\n                \"tool_version\": self.VERSION,\n                \"timestamp_utc\": datetime.now(timezone.utc).isoformat(),\n                \"session_path\": str(self.session_path),\n            }\n            self._save_json_sidecar(recipe_obj, recipe_filename)\n\n        for func_name, params in functions_and_params.items():\n            if not hasattr(self, func_name):\n                raise AttributeError(\n                    f\"Unknown preprocessing function '{func_name}'. \"\n                    f\"Available: {[m for m in dir(self) if not m.startswith('_')]}\"\n                )\n            fn = getattr(self, func_name)\n            if not isinstance(params, dict):\n                raise TypeError(\n                    f\"Parameters for '{func_name}' must be a dict, got {type(params)}\"\n                )\n            fn(**params)\n\n        # Save lightweight provenance after successful run\n        if log_recipe:\n            prov = {\n                \"completed_recipe\": list(functions_and_params.keys()),\n                \"tool_version\": self.VERSION,\n                \"timestamp_utc\": datetime.now(timezone.utc).isoformat(),\n                \"metadata\": self.metadata.to_dict(),\n            }\n            self._save_json_sidecar(prov, provenance_filename)\n</code></pre>"},{"location":"api_reference/#pyxations.pre_processing.PreProcessing.bad_samples","title":"<code>bad_samples(screen_height=None, screen_width=None, *, mark_nan_as_bad=True, inclusive_bounds=True)</code>","text":"<p>Mark rows as 'bad' if any available coordinate falls outside screen bounds. Applies to samples, fixations, saccades. (Blinks unaffected.)</p> <p>If width/height not provided, will use metadata.screen_* if available.</p> Source code in <code>pyxations/pre_processing.py</code> <pre><code>def bad_samples(\n    self,\n    screen_height: Optional[int] = None,\n    screen_width: Optional[int] = None,\n    *,\n    mark_nan_as_bad: bool = True,\n    inclusive_bounds: bool = True,\n) -&gt; None:\n    \"\"\"\n    Mark rows as 'bad' if any available coordinate falls outside screen bounds.\n    Applies to samples, fixations, saccades. (Blinks unaffected.)\n\n    If width/height not provided, will use metadata.screen_* if available.\n    \"\"\"\n    H = screen_height if screen_height is not None else self.metadata.screen_height\n    W = screen_width if screen_width is not None else self.metadata.screen_width\n    if H is None or W is None:\n        raise ValueError(\n            \"bad_samples requires screen_height and screen_width (either passed \"\n            \"or set via set_metadata()).\"\n        )\n\n    def _mark(df: pd.DataFrame) -&gt; pd.DataFrame:\n        d = df.copy()\n\n        # Gather candidate coordinate columns if present\n        coord_cols = self._ensure_columns_exist(\n            d,\n            [\n                \"LX\", \"LY\", \"RX\", \"RY\", \"X\", \"Y\",\n                \"xStart\", \"xEnd\", \"yStart\", \"yEnd\", \"xAvg\", \"yAvg\",\n            ],\n        )\n        if not coord_cols:\n            # If no coords present, default to 'not bad'\n            if \"bad\" not in d.columns:\n                d[\"bad\"] = False\n            return d\n\n        xcols = [c for c in coord_cols if c.lower().startswith(\"x\")]\n        ycols = [c for c in coord_cols if c.lower().startswith(\"y\")]\n\n        # Validity masks for each axis\n        if inclusive_bounds:\n            valid_w = np.logical_and.reduce([d[c].ge(0) &amp; d[c].le(W) for c in xcols]) if xcols else True\n            valid_h = np.logical_and.reduce([d[c].ge(0) &amp; d[c].le(H) for c in ycols]) if ycols else True\n        else:\n            valid_w = np.logical_and.reduce([d[c].gt(0) &amp; d[c].lt(W) for c in xcols]) if xcols else True\n            valid_h = np.logical_and.reduce([d[c].gt(0) &amp; d[c].lt(H) for c in ycols]) if ycols else True\n\n        bad = ~(valid_w &amp; valid_h)\n        if mark_nan_as_bad:\n            bad |= d[coord_cols].isna().any(axis=1)\n\n        d[\"bad\"] = bad.values\n        return d\n\n    self.samples = _mark(self.samples)\n    self.fixations = _mark(self.fixations)\n    self.saccades = _mark(self.saccades)\n</code></pre>"},{"location":"api_reference/#pyxations.pre_processing.PreProcessing.get_timestamps_from_messages","title":"<code>get_timestamps_from_messages(messages_dict, *, case_insensitive=True, use_regex=True, return_match_token=False)</code>","text":"<p>Extract ordered timestamps per phase by matching message substrings/patterns.</p> <p>Parameters:</p> Name Type Description Default <code>messages_dict</code> <code>dict</code> <p>e.g., {'trial': ['TRIAL_START', 'BEGIN_TRIAL'], 'stim': ['STIM_ONSET']}</p> required <code>case_insensitive</code> <code>bool</code> <p>If True, ignore case during matching.</p> <code>True</code> <code>use_regex</code> <code>bool</code> <p>If True, treat entries as regex patterns joined by '|'; otherwise escape literals.</p> <code>True</code> <code>return_match_token</code> <code>bool</code> <p>If True, also creates/updates a 'matched_token' column with the first matched pattern.</p> <code>False</code> <p>Returns:</p> Type Description <code>Dict[str, List[int]]</code> <p>Ordered timestamps in ms for each key.</p> Source code in <code>pyxations/pre_processing.py</code> <pre><code>def get_timestamps_from_messages(\n    self,\n    messages_dict: Dict[str, List[str]],\n    *,\n    case_insensitive: bool = True,\n    use_regex: bool = True,\n    return_match_token: bool = False,\n) -&gt; Dict[str, List[int]]:\n    \"\"\"\n    Extract ordered timestamps per phase by matching message substrings/patterns.\n\n    Parameters\n    ----------\n    messages_dict : dict\n        e.g., {'trial': ['TRIAL_START', 'BEGIN_TRIAL'], 'stim': ['STIM_ONSET']}\n    case_insensitive : bool\n        If True, ignore case during matching.\n    use_regex : bool\n        If True, treat entries as regex patterns joined by '|'; otherwise escape literals.\n    return_match_token : bool\n        If True, also creates/updates a 'matched_token' column with the first matched pattern.\n\n    Returns\n    -------\n    Dict[str, List[int]]\n        Ordered timestamps in ms for each key.\n    \"\"\"\n    df = self.user_messages\n    self._require_columns(df, [\"timestamp\", \"message\"], \"get_timestamps_from_messages\")\n\n    timestamps_dict: Dict[str, List[int]] = {}\n    flags = re.I if case_insensitive else 0\n\n    # Prepare an optional matched_token column for traceability\n    if return_match_token and \"matched_token\" not in df.columns:\n        df = df.copy()\n        df[\"matched_token\"] = pd.Series([None] * len(df), index=df.index)\n\n    for key, tokens in messages_dict.items():\n        if not tokens:\n            raise ValueError(f\"[{key}] Empty token list passed to get_timestamps_from_messages.\")\n        parts = tokens if use_regex else [re.escape(t) for t in tokens]\n        pat = re.compile(\"|\".join(parts), flags=flags)\n\n        hits = df[df[\"message\"].str.contains(pat, regex=True, na=False)].copy()\n        hits.sort_values(by=\"timestamp\", inplace=True)\n\n        if return_match_token and not hits.empty:\n            # record which token matched first for each hit\n            def _which(m: str) -&gt; Optional[str]:\n                for t in tokens:\n                    if (re.search(t, m, flags=flags) if use_regex else re.search(re.escape(t), m, flags=flags)):\n                        return t\n                return None\n\n            hits[\"matched_token\"] = hits[\"message\"].apply(_which)\n            # write back those rows (optional traceability)\n            df.loc[hits.index, \"matched_token\"] = hits[\"matched_token\"]\n\n        stamps = hits[\"timestamp\"].astype(int).tolist()\n        if len(stamps) == 0:\n            raise ValueError(\n                f\"[{key}] No timestamps found for messages {tokens} \"\n                f\"in session: {self.session_path}\"\n            )\n        timestamps_dict[key] = stamps\n\n    # Persist updated matched_token if requested\n    if return_match_token:\n        self.user_messages = df\n\n    return timestamps_dict\n</code></pre>"},{"location":"api_reference/#pyxations.pre_processing.PreProcessing.process","title":"<code>process(functions_and_params, *, log_recipe=True, recipe_filename='preprocessing_recipe.json', provenance_filename='preprocessing_provenance.json')</code>","text":"<p>Run a declarative preprocessing recipe, e.g.:     pp.process({         \"split_all_into_trials_by_msgs\": {             \"start_msgs\": {\"trial\": [\"TRIAL_START\"]},             \"end_msgs\": {\"trial\": [\"TRIAL_END\"]},         },         \"bad_samples\": {\"screen_height\": 1080, \"screen_width\": 1920},         \"saccades_direction\": {\"tol_deg\": 15},     })</p> <p>Unknown function names raise a helpful error.</p> Source code in <code>pyxations/pre_processing.py</code> <pre><code>def process(\n    self,\n    functions_and_params: Dict[str, Dict],\n    *,\n    log_recipe: bool = True,\n    recipe_filename: str = \"preprocessing_recipe.json\",\n    provenance_filename: str = \"preprocessing_provenance.json\",\n) -&gt; None:\n    \"\"\"\n    Run a declarative preprocessing recipe, e.g.:\n        pp.process({\n            \"split_all_into_trials_by_msgs\": {\n                \"start_msgs\": {\"trial\": [\"TRIAL_START\"]},\n                \"end_msgs\": {\"trial\": [\"TRIAL_END\"]},\n            },\n            \"bad_samples\": {\"screen_height\": 1080, \"screen_width\": 1920},\n            \"saccades_direction\": {\"tol_deg\": 15},\n        })\n\n    Unknown function names raise a helpful error.\n    \"\"\"\n    # Optional: save the declared recipe for exact reproducibility\n    if log_recipe:\n        recipe_obj = {\n            \"declared_recipe\": functions_and_params,\n            \"tool_version\": self.VERSION,\n            \"timestamp_utc\": datetime.now(timezone.utc).isoformat(),\n            \"session_path\": str(self.session_path),\n        }\n        self._save_json_sidecar(recipe_obj, recipe_filename)\n\n    for func_name, params in functions_and_params.items():\n        if not hasattr(self, func_name):\n            raise AttributeError(\n                f\"Unknown preprocessing function '{func_name}'. \"\n                f\"Available: {[m for m in dir(self) if not m.startswith('_')]}\"\n            )\n        fn = getattr(self, func_name)\n        if not isinstance(params, dict):\n            raise TypeError(\n                f\"Parameters for '{func_name}' must be a dict, got {type(params)}\"\n            )\n        fn(**params)\n\n    # Save lightweight provenance after successful run\n    if log_recipe:\n        prov = {\n            \"completed_recipe\": list(functions_and_params.keys()),\n            \"tool_version\": self.VERSION,\n            \"timestamp_utc\": datetime.now(timezone.utc).isoformat(),\n            \"metadata\": self.metadata.to_dict(),\n        }\n        self._save_json_sidecar(prov, provenance_filename)\n</code></pre>"},{"location":"api_reference/#pyxations.pre_processing.PreProcessing.saccades_direction","title":"<code>saccades_direction(tol_deg=15.0)</code>","text":"<p>Compute saccade angle (deg) and cardinal direction with tolerance bands.</p> <p>Parameters:</p> Name Type Description Default <code>tol_deg</code> <code>float</code> <p>Half-width of the acceptance band around 0\u00b0, \u00b190\u00b0, and \u00b1180\u00b0 for classifying right/left/up/down.</p> <code>15.0</code> Source code in <code>pyxations/pre_processing.py</code> <pre><code>def saccades_direction(self, tol_deg: float = 15.0) -&gt; None:\n    \"\"\"\n    Compute saccade angle (deg) and cardinal direction with tolerance bands.\n\n    Parameters\n    ----------\n    tol_deg : float\n        Half-width of the acceptance band around 0\u00b0, \u00b190\u00b0, and \u00b1180\u00b0\n        for classifying right/left/up/down.\n    \"\"\"\n    df = self.saccades.copy()\n    self._require_columns(\n        df, [\"xStart\", \"xEnd\", \"yStart\", \"yEnd\"], \"saccades_direction\"\n    )\n\n    x_dif = df[\"xEnd\"].astype(float) - df[\"xStart\"].astype(float)\n    y_dif = df[\"yEnd\"].astype(float) - df[\"yStart\"].astype(float)\n    deg = np.degrees(np.arctan2(y_dif.to_numpy(), x_dif.to_numpy()))\n    df[\"deg\"] = deg.astype(float)\n\n    # Tolerant direction bins\n    right = (-tol_deg &lt; df[\"deg\"]) &amp; (df[\"deg\"] &lt; tol_deg)\n    left = (df[\"deg\"] &gt; 180 - tol_deg) | (df[\"deg\"] &lt; -180 + tol_deg)\n    down = ((90 - tol_deg) &lt; df[\"deg\"]) &amp; (df[\"deg\"] &lt; (90 + tol_deg))\n    up = ((-90 - tol_deg) &lt; df[\"deg\"]) &amp; (df[\"deg\"] &lt; (-90 + tol_deg))\n\n    df[\"dir\"] = \"\"\n    df.loc[right, \"dir\"] = \"right\"\n    df.loc[left, \"dir\"] = \"left\"\n    df.loc[down, \"dir\"] = \"down\"\n    df.loc[up, \"dir\"] = \"up\"\n\n    self.saccades = df\n</code></pre>"},{"location":"api_reference/#pyxations.pre_processing.PreProcessing.save_metadata","title":"<code>save_metadata(filename='metadata.json')</code>","text":"<p>Persist metadata next to derivatives for reproducibility.</p> Source code in <code>pyxations/pre_processing.py</code> <pre><code>def save_metadata(self, filename: str = \"metadata.json\") -&gt; None:\n    \"\"\"Persist metadata next to derivatives for reproducibility.\"\"\"\n    self._save_json_sidecar(self.metadata.to_dict(), filename)\n</code></pre>"},{"location":"api_reference/#pyxations.pre_processing.PreProcessing.set_metadata","title":"<code>set_metadata(coords_unit=None, time_unit=None, pupil_unit=None, screen_width=None, screen_height=None, **extra)</code>","text":"<p>Update session-level metadata used in bounds checks and documentation.</p> Source code in <code>pyxations/pre_processing.py</code> <pre><code>def set_metadata(\n    self,\n    coords_unit: Optional[str] = None,\n    time_unit: Optional[str] = None,\n    pupil_unit: Optional[str] = None,\n    screen_width: Optional[int] = None,\n    screen_height: Optional[int] = None,\n    **extra,\n) -&gt; None:\n    \"\"\"Update session-level metadata used in bounds checks and documentation.\"\"\"\n    if coords_unit is not None:\n        self.metadata.coords_unit = coords_unit\n    if time_unit is not None:\n        self.metadata.time_unit = time_unit\n    if pupil_unit is not None:\n        self.metadata.pupil_unit = pupil_unit\n    if screen_width is not None:\n        self.metadata.screen_width = screen_width\n    if screen_height is not None:\n        self.metadata.screen_height = screen_height\n    self.metadata.extra.update(extra)\n</code></pre>"},{"location":"api_reference/#pyxations.pre_processing.PreProcessing.split_all_into_trials","title":"<code>split_all_into_trials(start_times, end_times, trial_labels=None, *, allow_open_last=True, require_nonoverlap=True)</code>","text":"<p>Segment samples/fixations/saccades/blinks using explicit times.</p> Source code in <code>pyxations/pre_processing.py</code> <pre><code>def split_all_into_trials(\n    self,\n    start_times: Dict[str, List[int]],\n    end_times: Dict[str, List[int]],\n    trial_labels: Optional[Dict[str, List[str]]] = None,\n    *,\n    allow_open_last: bool = True,\n    require_nonoverlap: bool = True,\n) -&gt; None:\n    \"\"\"Segment samples/fixations/saccades/blinks using explicit times.\"\"\"\n    for df in (self.samples, self.fixations, self.saccades, self.blinks):\n        self._split_into_trials_df(\n            df, start_times, end_times, trial_labels,\n            allow_open_last=allow_open_last,\n            require_nonoverlap=require_nonoverlap,\n        )\n</code></pre>"},{"location":"api_reference/#pyxations.pre_processing.PreProcessing.split_all_into_trials_by_durations","title":"<code>split_all_into_trials_by_durations(start_msgs, durations, trial_labels=None, **msg_kwargs)</code>","text":"<p>Segment using start message patterns and per-trial durations (ms).</p> Source code in <code>pyxations/pre_processing.py</code> <pre><code>def split_all_into_trials_by_durations(\n    self,\n    start_msgs: Dict[str, List[str]],\n    durations: Dict[str, List[int]],\n    trial_labels: Optional[Dict[str, List[str]]] = None,\n    **msg_kwargs,\n) -&gt; None:\n    \"\"\"Segment using start message patterns and per-trial durations (ms).\"\"\"\n    starts = self.get_timestamps_from_messages(start_msgs, **msg_kwargs)\n    end_times: Dict[str, List[int]] = {}\n    for key, durs in durations.items():\n        s = starts.get(key, [])\n        if len(durs) &lt; len(s):\n            raise ValueError(\n                f\"[{key}] Provided {len(durs)} durations but found {len(s)} start times \"\n                f\"in session: {self.session_path}\"\n            )\n        end_times[key] = [st + du for st, du in zip(s, durs)]\n    self.split_all_into_trials(starts, end_times, trial_labels)\n</code></pre>"},{"location":"api_reference/#pyxations.pre_processing.PreProcessing.split_all_into_trials_by_msgs","title":"<code>split_all_into_trials_by_msgs(start_msgs, end_msgs, trial_labels=None, **msg_kwargs)</code>","text":"<p>Segment tables using start and end message patterns.</p> Source code in <code>pyxations/pre_processing.py</code> <pre><code>def split_all_into_trials_by_msgs(\n    self,\n    start_msgs: Dict[str, List[str]],\n    end_msgs: Dict[str, List[str]],\n    trial_labels: Optional[Dict[str, List[str]]] = None,\n    **msg_kwargs,\n) -&gt; None:\n    \"\"\"Segment tables using start and end message patterns.\"\"\"\n    starts = self.get_timestamps_from_messages(start_msgs, **msg_kwargs)\n    ends = self.get_timestamps_from_messages(end_msgs, **msg_kwargs)\n    self.split_all_into_trials(starts, ends, trial_labels)\n</code></pre>"},{"location":"api_reference/#pyxations.pre_processing.SessionMetadata","title":"<code>SessionMetadata</code>  <code>dataclass</code>","text":"<p>Lightweight metadata container saved alongside derivatives.</p> Source code in <code>pyxations/pre_processing.py</code> <pre><code>@dataclass\nclass SessionMetadata:\n    \"\"\"Lightweight metadata container saved alongside derivatives.\"\"\"\n    coords_unit: str = \"px\"          # 'px' or 'deg'\n    time_unit: str = \"ms\"            # 'ms'\n    pupil_unit: str = \"arbitrary\"\n    screen_width: Optional[int] = None\n    screen_height: Optional[int] = None\n    extra: Dict[str, Union[str, int, float, bool, None]] = field(default_factory=dict)\n\n    def to_dict(self) -&gt; dict:\n        return {\n            \"coords_unit\": self.coords_unit,\n            \"time_unit\": self.time_unit,\n            \"pupil_unit\": self.pupil_unit,\n            \"screen_width\": self.screen_width,\n            \"screen_height\": self.screen_height,\n            \"extra\": self.extra,\n        }\n</code></pre>"},{"location":"api_reference/#bids_formatting","title":"bids_formatting","text":""},{"location":"api_reference/#pyxations.bids_formatting.dataset_to_bids","title":"<code>dataset_to_bids(target_folder_path, files_folder_path, dataset_name, session_substrings=1, format_name='eyelink')</code>","text":"<p>Convert a dataset to BIDS format.</p> <p>Args:     target_folder_path (str): Path to the folder where the BIDS dataset will be created.     files_folder_path (str): Path to the folder containing the EDF files.     The EDF files are assumed to have the ID of the subject at the beginning of the file name, separated by an underscore.     dataset_name (str): Name of the BIDS dataset.     session_substrings (int): Number of substrings to use for the session ID. Default is 1.</p> <p>Returns:     None</p> Source code in <code>pyxations/bids_formatting.py</code> <pre><code>def dataset_to_bids(target_folder_path, files_folder_path, dataset_name, session_substrings=1, format_name='eyelink'):\n    \"\"\"\n    Convert a dataset to BIDS format.\n\n    Args:\n        target_folder_path (str): Path to the folder where the BIDS dataset will be created.\n        files_folder_path (str): Path to the folder containing the EDF files.\n        The EDF files are assumed to have the ID of the subject at the beginning of the file name, separated by an underscore.\n        dataset_name (str): Name of the BIDS dataset.\n        session_substrings (int): Number of substrings to use for the session ID. Default is 1.\n\n    Returns:\n        None\n    \"\"\"\n    converter = get_converter(format_name)\n\n    # Create a metadata tsv file\n    metadata = pd.DataFrame(columns=['subject_id', 'old_subject_id'])\n    files_folder_path = Path(files_folder_path)\n    # List all file paths in the folder\n    file_paths = []\n    for file_path in files_folder_path.rglob('*'):  # Recursively go through all files\n        if file_path.is_file():\n            file_paths.append(file_path)\n\n    file_paths = [file for file in file_paths if file.suffix.lower() in converter.relevant_extensions()]\n\n    bids_folder_path = Path(target_folder_path) / dataset_name\n    bids_folder_path.mkdir(parents=True, exist_ok=True)\n\n    subj_ids = converter.get_subject_ids(file_paths)\n\n    # If all of the subjects have numerical IDs, sort them numerically, else sort them alphabetically\n    if all(subject_id.isdigit() for subject_id in subj_ids):\n        subj_ids.sort(key=int)\n    else:\n        subj_ids.sort()\n    new_subj_ids = [str(subject_index).zfill(4) for subject_index in range(1, len(subj_ids) + 1)]\n\n    # Create subfolders for each session for each subject\n    for subject_id in new_subj_ids:\n        old_subject_id = subj_ids[int(subject_id) - 1]\n        for file in file_paths:\n            file_name = Path(file).name\n            session_id = \"_\".join(\"\".join(file_name.split(\".\")[:-1]).split(\"_\")[1:session_substrings + 1])\n            converter.move_file_to_bids_folder(file, bids_folder_path, subject_id, old_subject_id, session_id)\n\n        metadata.loc[len(metadata.index)] = [subject_id, old_subject_id]\n    # Save metadata to tsv file\n    metadata.to_csv(bids_folder_path / \"participants.tsv\", sep=\"\\t\", index=False)\n    return bids_folder_path\n</code></pre>"},{"location":"api_reference/#eye_movement_detection","title":"eye_movement_detection","text":""},{"location":"api_reference/#visualization","title":"visualization","text":""},{"location":"api_reference/#utils","title":"utils","text":""},{"location":"api_reference/#pyxations.visualization.visualization.Visualization","title":"<code>Visualization</code>","text":"Source code in <code>pyxations/visualization/visualization.py</code> <pre><code>class Visualization():\n    def __init__(self, derivatives_folder_path,events_detection_algorithm):\n        self.derivatives_folder_path = Path(derivatives_folder_path)\n        if events_detection_algorithm not in EYE_MOVEMENT_DETECTION_DICT and events_detection_algorithm != 'eyelink':\n            raise ValueError(f\"Detection algorithm {events_detection_algorithm} not found.\")\n        self.events_detection_folder = Path(events_detection_algorithm+'_events')\n\n    def scanpath(\n        self,\n        fixations: pl.DataFrame,\n        screen_height: int,\n        screen_width: int,\n        folder_path: str | Path | None = None,\n        tmin: int | None = None,\n        tmax: int | None = None,\n        saccades: pl.DataFrame | None = None,\n        samples: pl.DataFrame | None = None,\n        phase_data: dict[str, dict] | None = None,\n        display: bool = True,\n    ):\n        \"\"\"\n        Fast scan\u2011path visualiser.\n\n        \u2022 **Vectorised**: no per\u2011row Python loops  \n        \u2022 **Single pass** phase grouping  \n        \u2022 Uses `BrokenBarHCollection` for fixation spans  \n        \u2022 Optional asynchronous PNG write via ThreadPoolExecutor (drop\u2011in\u2011ready, see comment)\n\n        Parameters\n        ----------\n        fixations\n            Polars DataFrame with at least `tStart`, `duration`, `xAvg`, `yAvg`, `phase`.\n        screen_height, screen_width\n            Stimulus resolution in pixels.\n        folder_path\n            Directory where 1 PNG per phase will be stored.  If *None*, nothing is saved.\n        tmin, tmax\n            Time window in **ms**.  If both `None`, the whole trial is plotted.\n        saccades\n            Polars DataFrame with `tStart`, `phase`, \u2026  (optional).\n        samples\n            Polars DataFrame with gaze traces (`tSample`, `LX`, `LY`, `RX`, `RY` or\n            `X`, `Y`) (optional).\n        phase_data\n            Per\u2011phase extras::\n\n                {\n                    \"search\": {\n                        \"img_paths\": [...],\n                        \"img_plot_coords\": [(x1,y1,x2,y2), ...],\n                        \"bbox\": (x1,y1,x2,y2),\n                    },\n                    ...\n                }\n\n        display\n            If *False* the figure canvas is never shown (faster for batch jobs).\n        \"\"\"\n\n\n        # ------------- small helpers ------------------------------------------------\n        def _make_axes(plot_samples: bool):\n            if plot_samples:\n                fig, (ax_main, ax_gaze) = plt.subplots(\n                    2, 1, height_ratios=(4, 1), figsize=(10, 6), sharex=False\n                )\n            else:\n                fig, ax_main = plt.subplots(figsize=(10, 6))\n                ax_gaze = None\n            ax_main.set_xlim(0, screen_width)\n            ax_main.set_ylim(screen_height, 0)\n            return fig, ax_main, ax_gaze\n\n        def _maybe_cache_img(path):\n            \"\"\"Load image from disk with a small LRU cache.\"\"\"\n\n            # Cache hit: move to the end (most recently used)\n            if path in _img_cache:\n                img = _img_cache.pop(path)\n                _img_cache[path] = img\n                return img\n\n            # Cache miss: load image\n            img = mpimg.imread(path)\n\n            # Optional: reduce memory if image is float64 in [0, 1]\n            if isinstance(img, np.ndarray) and img.dtype == np.float64:\n                img = (img * 255).clip(0, 255).astype(np.uint8)\n\n            # Insert into cache\n            _img_cache[path] = img\n\n            # If cache too big, drop least recently used item\n            if len(_img_cache) &gt; _MAX_CACHE_ITEMS:\n                _img_cache.popitem(last=False)  # pops the oldest inserted item\n\n            return img\n\n        # ---------------------------------------------------------------------------\n        plot_saccades = saccades is not None\n        plot_samples = samples is not None\n        _img_cache = OrderedDict()\n        _MAX_CACHE_ITEMS = 8  # or 5, 10, etc. Tune as you like.\n\n        trial_idx = fixations[\"trial_number\"][0]\n\n        # ---- time filter ----------------------------------------------------------\n        if tmin is not None and tmax is not None:\n            fixations = fixations.filter(pl.col(\"tStart\").is_between(tmin, tmax))\n            if plot_saccades:\n                saccades = saccades.filter(pl.col(\"tStart\").is_between(tmin, tmax))\n            if plot_samples:\n                samples = samples.filter(pl.col(\"tSample\").is_between(tmin, tmax))\n\n        # remove empty phase markings\n        fixations = fixations.filter(pl.col(\"phase\") != \"\")\n        if plot_saccades:\n            saccades = saccades.filter(pl.col(\"phase\") != \"\")\n        if plot_samples:\n            samples = samples.filter(pl.col(\"phase\") != \"\")\n\n        # ---- split once by phase --------------------------------------------------\n        fix_by_phase = fixations.partition_by(\"phase\", as_dict=True)\n        sac_by_phase = (\n            saccades.partition_by(\"phase\", as_dict=True) if plot_saccades else {}\n        )\n        samp_by_phase = (\n            samples.partition_by(\"phase\", as_dict=True) if plot_samples else {}\n        )\n\n        # colour map shared across phases\n        cmap = plt.cm.rainbow\n\n        # ---- build &amp; draw ---------------------------------------------------------\n        # optional async saver (uncomment if you save hundreds of files)\n        from concurrent.futures import ThreadPoolExecutor\n        saver = ThreadPoolExecutor(max_workers=4) if folder_path else None\n\n        if not display:\n            plt.ioff()\n\n        for phase, phase_fix in fix_by_phase.items():\n            if phase_fix.is_empty():\n                continue\n\n            # ---------- vectors (zero\u2011copy) -----------------\n            fx, fy, fdur = phase_fix.select([\"xAvg\", \"yAvg\", \"duration\"]).to_numpy().T\n            n_fix = fx.size\n            fix_idx = np.arange(1, n_fix + 1)\n\n            norm = mplcolors.BoundaryNorm(np.arange(1, n_fix + 2), cmap.N)\n\n            # saccades\n            sac_t = (\n                sac_by_phase[phase][\"tStart\"].to_numpy()\n                if plot_saccades and phase in sac_by_phase\n                else np.empty(0)\n            )\n\n            # samples\n            if plot_samples and phase in samp_by_phase and samp_by_phase[phase].height:\n                samp_phase = samp_by_phase[phase]\n                t0 = samp_phase[\"tSample\"][0]\n                ts = (samp_phase[\"tSample\"].to_numpy() - t0) \n                get = samp_phase.get_column\n                lx = get(\"LX\").to_numpy() if \"LX\" in samp_phase.columns else None\n                ly = get(\"LY\").to_numpy() if \"LY\" in samp_phase.columns else None\n                rx = get(\"RX\").to_numpy() if \"RX\" in samp_phase.columns else None\n                ry = get(\"RY\").to_numpy() if \"RY\" in samp_phase.columns else None\n                gx = get(\"X\").to_numpy() if \"X\" in samp_phase.columns else None\n                gy = get(\"Y\").to_numpy() if \"Y\" in samp_phase.columns else None\n            else:\n                t0 = None\n\n            # ---------- figure -----------------------------\n            fig, ax_main, ax_gaze = _make_axes(plot_samples and t0 is not None)\n            # scatter fixations\n            sc = ax_main.scatter(\n                fx,\n                fy,\n                c=fix_idx,\n                s=fdur,\n                cmap=cmap,\n                norm=norm,\n                alpha=0.5,\n                zorder=2,\n            )\n            fig.colorbar(\n                sc,\n                ax=ax_main,\n                ticks=[1, n_fix // 2 if n_fix &gt; 2 else n_fix, n_fix],\n                fraction=0.046,\n                pad=0.04,\n            ).set_label(\"# of fixation\")\n\n            # ---------- stimulus imagery / bbox ------------\n            if phase_data and phase[0] in phase_data:\n                pdict = phase_data[phase[0]]\n                coords = pdict.get(\"img_plot_coords\") or []\n                bbox = pdict.get('bbox',None) \n                for img_path, box in zip(pdict.get(\"img_paths\", []), coords):\n\n                    ax_main.imshow(_maybe_cache_img(img_path), extent=[box[0], box[2], box[3], box[1]], zorder=0)\n                if bbox is not None:\n                    x1, y1, x2, y2 = bbox\n                    ax_main.plot([x1, x2, x2, x1, x1], [y1, y1, y2, y2, y1], color='red', linewidth=1.5, zorder=3)\n\n            # ---------- gaze traces ------------------------\n            if ax_gaze is not None:\n                if lx is not None:\n                    ax_main.plot(lx, ly, \"--\", color=\"C0\", zorder=1)\n                    ax_gaze.plot(ts, lx, label=\"Left\u202fX\")\n                    ax_gaze.plot(ts, ly, label=\"Left\u202fY\")\n                if rx is not None:\n                    ax_main.plot(rx, ry, \"--\", color=\"k\", zorder=1)\n                    ax_gaze.plot(ts, rx, label=\"Right\u202fX\")\n                    ax_gaze.plot(ts, ry, label=\"Right\u202fY\")\n                if gx is not None:\n                    ax_main.plot(gx, gy, \"--\", color=\"k\", zorder=1, alpha=0.6)\n                    ax_gaze.plot(ts, gx, label=\"X\")\n                    ax_gaze.plot(ts, gy, label=\"Y\")\n\n                # fixation spans\n                bars   = np.c_[phase_fix['tStart'].to_numpy() - t0,\n                            phase_fix['duration'].to_numpy()]\n                height = ax_gaze.get_ylim()[1] - ax_gaze.get_ylim()[0]\n                colors = cmap(norm(fix_idx))\n\n                # Draw all bars in one call; no BrokenBarHCollection import needed\n                ax_gaze.broken_barh(bars, (0, height), facecolors=colors, alpha=0.4)\n                # saccades\n                if sac_t.size:\n                    ymin, ymax = ax_gaze.get_ylim()\n                    ax_gaze.vlines(\n                        sac_t - t0,\n                        ymin,\n                        ymax,\n                        colors=\"red\",\n                        linestyles=\"--\",\n                        linewidth=0.8,\n                    )\n\n                # tidy gaze axis\n                h, l = ax_gaze.get_legend_handles_labels()\n                by_label = {lab: hdl for hdl, lab in zip(h, l)}\n                ax_gaze.legend(\n                    by_label.values(),\n                    by_label.keys(),\n                    loc=\"center left\",\n                    bbox_to_anchor=(1, 0.5),\n                )\n                ax_gaze.set_ylabel(\"Gaze\")\n                ax_gaze.set_xlabel(\"Time [s]\")\n\n            fig.tight_layout()\n\n            # ---------- save / show ------------------------\n            if folder_path:\n                scan_name = f\"scanpath_{trial_idx}\"\n                if tmin is not None and tmax is not None:\n                    scan_name += f\"_{tmin}_{tmax}\"\n                out = Path(folder_path) / f\"{scan_name}_{phase[0]}.png\"\n                fig.savefig(out, dpi=150)\n                if saver:  saver.submit(fig.savefig, out, dpi=150)\n\n            if display:\n                plt.show()\n            plt.close(fig)\n\n        if not display:\n            plt.ion()\n\n\n    def fix_duration(self,fixations:pl.DataFrame,axs=None):\n\n        ax = axs\n        if ax is None:\n            fig, ax = plt.subplots()\n\n        ax.hist(fixations.select(pl.col('duration')).to_numpy().ravel(), bins=100, edgecolor='black', linewidth=1.2, density=True)\n        ax.set_title('Fixation duration')\n        ax.set_xlabel('Time (ms)')\n        ax.set_ylabel('Density')\n\n\n    def sacc_amplitude(self,saccades:pl.DataFrame,axs=None):\n\n        ax = axs\n        if ax is None:\n            fig, ax = plt.subplots()\n\n        saccades_amp = saccades.select(pl.col('ampDeg')).to_numpy().ravel()\n        ax.hist(saccades_amp, bins=100, range=(0, 20), edgecolor='black', linewidth=1.2, density=True)\n        ax.set_title('Saccades amplitude')\n        ax.set_xlabel('Amplitude (deg)')\n        ax.set_ylabel('Density')\n\n\n    def sacc_direction(self,saccades:pl.DataFrame,axs=None,figs=None):\n\n        ax = axs\n        if ax is None:\n            fig = plt.figure()\n            ax = plt.subplot(polar=True)\n        else:\n            ax.set_axis_off()\n            ax = figs.add_subplot(2, 2, 3, projection='polar')\n        if 'deg' not in saccades.columns or 'dir' not in saccades.columns:\n            raise ValueError('Compute saccades direction first by using saccades_direction function from the PreProcessing module.')\n        # Convert from deg to rad\n        saccades_rad = saccades.select(pl.col('deg')).to_numpy().ravel() * np.pi / 180\n\n        n_bins = 24\n        ang_hist, bin_edges = np.histogram(saccades_rad, bins=24, density=True)\n        bin_centers = [np.mean((bin_edges[i], bin_edges[i+1])) for i in range(len(bin_edges) - 1)]\n\n        bars = ax.bar(bin_centers, ang_hist, width=2*np.pi/n_bins, bottom=0.0, alpha=0.4, edgecolor='black')\n        ax.set_title('Saccades direction')\n        ax.set_yticklabels([])\n\n        for r, bar in zip(ang_hist, bars):\n            bar.set_facecolor(plt.cm.Blues(r / np.max(ang_hist)))\n\n\n    def sacc_main_sequence(self,saccades:pl.DataFrame,axs=None, hline=None):\n\n        ax = axs\n        if ax is None:\n            fig, ax = plt.subplots()\n        # Logarithmic bins\n        XL = np.log10(25)  # Adjusted to fit the xlim\n        YL = np.log10(1000)  # Adjusted to fit the ylim\n\n        saccades_peak_vel = saccades.select(pl.col('vPeak')).to_numpy().ravel()\n        saccades_amp = saccades.select(pl.col('ampDeg')).to_numpy().ravel()\n\n        # Create a 2D histogram with logarithmic bins\n        ax.hist2d(saccades_amp, saccades_peak_vel, bins=[np.logspace(-1, XL, 50), np.logspace(0, YL, 50)])\n\n        if hline:\n            ax.hlines(y=hline, xmin=ax.get_xlim()[0], xmax=ax.get_xlim()[1], colors='grey', linestyles='--', label=hline)\n            ax.legend()\n        ax.set_yscale('log')\n        ax.set_xscale('log')\n        ax.set_title('Main sequence')\n        ax.set_xlabel('Amplitude (deg)')\n        ax.set_ylabel('Peak velocity (deg)')\n         # Set the limits of the axes\n        ax.set_xlim(0.1, 25)\n        ax.set_ylim(10, 1000)\n        ax.set_aspect('equal')\n\n\n    def plot_multipanel(\n            self,\n            fixations: pl.DataFrame,\n            saccades: pl.DataFrame,\n            display: bool = True\n        ) -&gt; None:\n        \"\"\"\n        Create a 2\u00d72 multi\u2011panel diagnostic plot for every non\u2011empty\n        phase label and save it as PNG in\n        &lt;derivatives_folder_path&gt;/&lt;events_detection_folder&gt;/plots/.\n        \"\"\"\n        # \u2500\u2500 paths &amp; matplotlib style \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n        folder_path: Path = (\n            self.derivatives_folder_path\n            / self.events_detection_folder\n            / \"plots\"\n        )\n        folder_path.mkdir(parents=True, exist_ok=True)\n        plt.rcParams.update({\"font.size\": 12})\n\n        # \u2500\u2500 drop practice / invalid trials \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n        fixations = fixations.filter(pl.col(\"trial_number\") != -1)\n        saccades  = saccades.filter(pl.col(\"trial_number\") != -1)\n\n        # \u2500\u2500 collect valid phase labels (skip empty string) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n        phases = (\n            fixations\n            .select(pl.col(\"phase\").filter(pl.col(\"phase\") != \"\"))\n            .unique()           # unique values in this Series\n            .to_series()\n            .to_list()          # plain Python list of strings\n        )\n\n        # \u2500\u2500 one figure per phase \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n        for phase in phases:\n            fix_phase   = fixations.filter(pl.col(\"phase\") == phase)\n            sacc_phase  = saccades.filter(pl.col(\"phase\") == phase)\n\n            fig, axs = plt.subplots(2, 2, figsize=(12, 7))\n\n            self.fix_duration(fix_phase , axs=axs[0, 0])\n            self.sacc_main_sequence(sacc_phase, axs=axs[1, 1])\n            self.sacc_direction(sacc_phase, axs=axs[1, 0], figs=fig)\n            self.sacc_amplitude(sacc_phase, axs=axs[0, 1])\n\n            fig.tight_layout()\n            plt.savefig(folder_path / f\"multipanel_{phase}.png\")\n            if display:\n                plt.show()\n            plt.close()\n\n    def plot_animation(\n        self,\n        samples: pl.DataFrame,\n        screen_height: int,\n        screen_width: int,\n        video_path: str | Path | None = None,\n        background_image_path: str | Path | None = None,\n        folder_path: str | Path | None = None,\n        tmin: int | None = None,\n        tmax: int | None = None,\n        seconds_to_show: float | None = None,\n        scale_factor: float = 0.5,\n        gaze_radius: int = 10,\n        gaze_color: tuple = (255, 0, 0),\n        fps: float | None = None,\n        output_format: str = \"matplotlib\",\n        display: bool = True,\n    ):\n        \"\"\"\n        Create an animated visualization of eye-tracking data.\n\n        When a video is provided, the animation syncs gaze samples with video frames.\n        When no video is provided, gaze points are animated on a grey background or\n        a provided background image, using the sample timestamps for timing.\n\n        Parameters\n        ----------\n        samples\n            Polars DataFrame with gaze samples. Must contain 'tSample' and gaze\n            position columns ('X', 'Y' or 'LX', 'LY', 'RX', 'RY').\n        screen_height, screen_width\n            Stimulus resolution in pixels.\n        video_path\n            Path to a video file. If provided, gaze is overlaid on video frames.\n        background_image_path\n            Path to a background image. Only used when video_path is None.\n            If both are None, a grey background is used.\n        folder_path\n            Directory where the animation will be saved. If None, nothing is saved.\n            The file format depends on `output_format`.\n        tmin, tmax\n            Time window in **ms**. If both None, the whole trial is plotted.\n        seconds_to_show\n            Limit the animation to the first N seconds. If None, shows all available data.\n        scale_factor\n            Resolution scaling factor (1.0 = original, 0.5 = half resolution).\n        gaze_radius\n            Radius of the gaze point circle in pixels (before scaling).\n        gaze_color\n            RGB tuple for gaze point color.\n        fps\n            Frames per second for the animation. If None:\n            - With video: uses the video's native FPS\n            - Without video: defaults to 60 FPS\n        output_format\n            Output format for saved animations:\n            - \"html\": Interactive HTML file (default, works in browsers)\n            - \"mp4\": Video file (requires ffmpeg)\n            - \"gif\": Animated GIF file (requires pillow)\n            - \"matplotlib\": Show in matplotlib GUI window (blocking)\n        display\n            If True and output_format is \"html\", returns an HTML object for notebooks.\n            If output_format is \"matplotlib\", this is ignored (always shows window).\n            If False, only saves to file (if folder_path is provided).\n\n        Returns\n        -------\n        IPython.display.HTML or None\n            Returns HTML animation if display=True and output_format=\"html\", otherwise None.\n        \"\"\"\n        try:\n            import cv2\n            from matplotlib.animation import FuncAnimation\n            import matplotlib as mpl\n            mpl.rcParams['animation.embed_limit'] = 100\n        except ImportError as e:\n            raise ImportError(\n                f\"Missing required dependency for animation: {e}. \"\n                \"Please install cv2 (opencv-python).\"\n            )\n\n        # Validate output_format\n        valid_formats = [\"html\", \"mp4\", \"gif\", \"matplotlib\"]\n        if output_format not in valid_formats:\n            raise ValueError(f\"output_format must be one of {valid_formats}, got '{output_format}'\")\n\n        # ---- Determine gaze columns ----\n        if \"X\" in samples.columns and \"Y\" in samples.columns:\n            x_col, y_col = \"X\", \"Y\"\n        elif \"LX\" in samples.columns and \"LY\" in samples.columns:\n            x_col, y_col = \"LX\", \"LY\"\n        elif \"RX\" in samples.columns and \"RY\" in samples.columns:\n            x_col, y_col = \"RX\", \"RY\"\n        else:\n            raise ValueError(\"Samples DataFrame must contain gaze columns (X, Y) or (LX, LY) or (RX, RY)\")\n\n        # ---- Time filter ----\n        if tmin is not None and tmax is not None:\n            samples = samples.filter(pl.col(\"tSample\").is_between(tmin, tmax))\n\n        if samples.is_empty():\n            raise ValueError(\"No samples available after time filtering\")\n\n        # ---- Drop NaN gaze values ----\n        samples = samples.filter(pl.col(x_col).is_not_null() &amp; pl.col(y_col).is_not_null())\n\n        # ---- Calculate scaled dimensions ----\n        scaled_width = int(screen_width * scale_factor)\n        scaled_height = int(screen_height * scale_factor)\n\n        trial_idx = samples[\"trial_number\"][0] if \"trial_number\" in samples.columns else 0\n\n        # ================= WITH VIDEO =================\n        if video_path is not None:\n            video_path = Path(video_path)\n            if not video_path.exists():\n                raise FileNotFoundError(f\"Video file not found: {video_path}\")\n\n            cap = cv2.VideoCapture(str(video_path))\n            video_fps = cap.get(cv2.CAP_PROP_FPS)\n            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n            video_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n            video_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\n            if fps is None:\n                fps = video_fps\n\n            # Calculate time to frame mapping\n            t_start = samples[\"tSample\"].min()\n            t_end = samples[\"tSample\"].max()\n            trial_duration = t_end - t_start\n\n            # Create frame-to-time mapping\n            frame_edges = np.linspace(t_start, t_end, total_frames + 1)\n            frame_times = ((frame_edges[:-1] + frame_edges[1:]) / 2).astype(int)\n\n            # Build a lookup: frame_index -&gt; list of gaze points\n            samples_np = samples.select([x_col, y_col, \"tSample\"]).to_numpy()\n            gaze_by_frame = {i: [] for i in range(total_frames)}\n\n            for x, y, t in samples_np:\n                # Find the closest frame\n                frame_idx = np.searchsorted(frame_times, t, side='right') - 1\n                frame_idx = max(0, min(frame_idx, total_frames - 1))\n                gaze_by_frame[frame_idx].append((x, y))\n\n            # Limit frames if seconds_to_show is set\n            frames_to_show = total_frames\n            if seconds_to_show is not None:\n                frames_to_show = min(int(fps * seconds_to_show), total_frames)\n\n            # Reset video\n            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n\n            # Create figure\n            fig, ax = plt.subplots(figsize=(10 * scale_factor, 6 * scale_factor))\n            ax.axis('off')\n\n            # Initialize with first frame\n            ret, frame = cap.read()\n            if not ret:\n                cap.release()\n                raise RuntimeError(\"Could not read first frame from video\")\n\n            frame_resized = cv2.resize(frame, (scaled_width, scaled_height), interpolation=cv2.INTER_AREA)\n            frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n            im = ax.imshow(frame_rgb)\n\n            def update_frame_video(frame_idx):\n                ret, frame = cap.read()\n                if not ret:\n                    return [im]\n\n                frame_resized = cv2.resize(frame, (scaled_width, scaled_height), interpolation=cv2.INTER_AREA)\n                frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n\n                # Draw gaze points for this frame\n                for gx, gy in gaze_by_frame.get(frame_idx, []):\n                    scaled_x = int(gx * scale_factor)\n                    scaled_y = int(gy * scale_factor)\n                    if 0 &lt;= scaled_x &lt; scaled_width and 0 &lt;= scaled_y &lt; scaled_height:\n                        radius = max(3, int(gaze_radius * scale_factor))\n                        cv2.circle(frame_rgb, (scaled_x, scaled_y), radius=radius, color=gaze_color, thickness=-1)\n\n                im.set_array(frame_rgb)\n                return [im]\n\n            anim = FuncAnimation(fig, update_frame_video, frames=frames_to_show,\n                                 interval=1000/fps, blit=True, repeat=True)\n\n        # ================= WITHOUT VIDEO =================\n        else:\n            if fps is None:\n                fps = 60  # Default FPS for sample-based animation\n\n            # Prepare background\n            if background_image_path is not None:\n                bg_path = Path(background_image_path)\n                if not bg_path.exists():\n                    raise FileNotFoundError(f\"Background image not found: {bg_path}\")\n                bg_img = mpimg.imread(str(bg_path))\n                if bg_img.dtype == np.float64:\n                    bg_img = (bg_img * 255).clip(0, 255).astype(np.uint8)\n                # Resize background to match screen dimensions then scale\n                bg_img = cv2.resize(bg_img, (scaled_width, scaled_height), interpolation=cv2.INTER_AREA)\n            else:\n                # Grey background\n                bg_img = np.ones((scaled_height, scaled_width, 3), dtype=np.uint8) * 128\n\n            # Get time range\n            t_start = samples[\"tSample\"].min()\n            t_end = samples[\"tSample\"].max()\n            trial_duration = t_end - t_start\n\n            # Limit duration if seconds_to_show is set\n            if seconds_to_show is not None:\n                t_end = min(t_end, t_start + int(seconds_to_show * 1000))\n                samples = samples.filter(pl.col(\"tSample\") &lt;= t_end)\n                trial_duration = t_end - t_start\n\n            # Calculate total frames based on duration and fps\n            total_frames = int((trial_duration / 1000) * fps)\n            if total_frames &lt; 1:\n                total_frames = 1\n\n            # Create time bins for each animation frame\n            frame_times = np.linspace(t_start, t_end, total_frames + 1)\n\n            # Build gaze lookup by frame\n            samples_np = samples.select([x_col, y_col, \"tSample\"]).to_numpy()\n            gaze_by_frame = {i: [] for i in range(total_frames)}\n\n            for x, y, t in samples_np:\n                frame_idx = np.searchsorted(frame_times, t, side='right') - 1\n                frame_idx = max(0, min(frame_idx, total_frames - 1))\n                gaze_by_frame[frame_idx].append((x, y))\n\n            # Create figure\n            fig, ax = plt.subplots(figsize=(10 * scale_factor, 6 * scale_factor))\n            ax.axis('off')\n\n            # Initialize with background\n            im = ax.imshow(bg_img.copy())\n\n            def update_frame_no_video(frame_idx):\n                # Start with fresh background copy\n                frame_rgb = bg_img.copy()\n\n                # Draw gaze points for this frame\n                for gx, gy in gaze_by_frame.get(frame_idx, []):\n                    scaled_x = int(gx * scale_factor)\n                    scaled_y = int(gy * scale_factor)\n                    if 0 &lt;= scaled_x &lt; scaled_width and 0 &lt;= scaled_y &lt; scaled_height:\n                        radius = max(3, int(gaze_radius * scale_factor))\n                        cv2.circle(frame_rgb, (scaled_x, scaled_y), radius=radius, color=gaze_color, thickness=-1)\n\n                im.set_array(frame_rgb)\n                return [im]\n\n            anim = FuncAnimation(fig, update_frame_no_video, frames=total_frames,\n                                 interval=1000/fps, blit=True, repeat=True)\n\n        # ================= SAVE / DISPLAY =================\n        result = None\n        trial_idx_val = trial_idx\n\n        # Build output filename\n        anim_name = f\"animation_{trial_idx_val}\"\n        if tmin is not None and tmax is not None:\n            anim_name += f\"_{tmin}_{tmax}\"\n\n        # Handle different output formats\n        if output_format == \"matplotlib\":\n            # Show in matplotlib GUI window (blocking)\n            plt.show()\n            # Cleanup video capture if used\n            if video_path is not None:\n                cap.release()\n            return None\n\n        elif output_format == \"mp4\":\n            if folder_path:\n                folder_path = Path(folder_path)\n                folder_path.mkdir(parents=True, exist_ok=True)\n                out_path = folder_path / f\"{anim_name}.mp4\"\n                try:\n                    anim.save(str(out_path), writer='ffmpeg', fps=fps)\n                    print(f\"Animation saved to: {out_path}\")\n                except Exception as e:\n                    raise RuntimeError(\n                        f\"Failed to save MP4. Make sure ffmpeg is installed. Error: {e}\"\n                    )\n            plt.close(fig)\n\n        elif output_format == \"gif\":\n            if folder_path:\n                folder_path = Path(folder_path)\n                folder_path.mkdir(parents=True, exist_ok=True)\n                out_path = folder_path / f\"{anim_name}.gif\"\n                try:\n                    anim.save(str(out_path), writer='pillow', fps=fps)\n                    print(f\"Animation saved to: {out_path}\")\n                except Exception as e:\n                    raise RuntimeError(\n                        f\"Failed to save GIF. Make sure pillow is installed. Error: {e}\"\n                    )\n            plt.close(fig)\n\n        else:  # html (default)\n            if folder_path:\n                folder_path = Path(folder_path)\n                folder_path.mkdir(parents=True, exist_ok=True)\n                out_path = folder_path / f\"{anim_name}.html\"\n                with open(out_path, 'w') as f:\n                    f.write(anim.to_jshtml())\n                print(f\"Animation saved to: {out_path}\")\n\n            if display:\n                try:\n                    from IPython.display import HTML\n                    plt.close(fig)\n                    result = HTML(anim.to_jshtml())\n                except ImportError:\n                    print(\"IPython not available. Use output_format='matplotlib' for GUI display.\")\n                    plt.close(fig)\n            else:\n                plt.close(fig)\n\n        # Cleanup video capture if used\n        if video_path is not None:\n            cap.release()\n\n        return result\n</code></pre>"},{"location":"api_reference/#pyxations.visualization.visualization.Visualization.plot_animation","title":"<code>plot_animation(samples, screen_height, screen_width, video_path=None, background_image_path=None, folder_path=None, tmin=None, tmax=None, seconds_to_show=None, scale_factor=0.5, gaze_radius=10, gaze_color=(255, 0, 0), fps=None, output_format='matplotlib', display=True)</code>","text":"<p>Create an animated visualization of eye-tracking data.</p> <p>When a video is provided, the animation syncs gaze samples with video frames. When no video is provided, gaze points are animated on a grey background or a provided background image, using the sample timestamps for timing.</p> <p>Parameters:</p> Name Type Description Default <code>samples</code> <code>DataFrame</code> <p>Polars DataFrame with gaze samples. Must contain 'tSample' and gaze position columns ('X', 'Y' or 'LX', 'LY', 'RX', 'RY').</p> required <code>screen_height</code> <code>int</code> <p>Stimulus resolution in pixels.</p> required <code>screen_width</code> <code>int</code> <p>Stimulus resolution in pixels.</p> required <code>video_path</code> <code>str | Path | None</code> <p>Path to a video file. If provided, gaze is overlaid on video frames.</p> <code>None</code> <code>background_image_path</code> <code>str | Path | None</code> <p>Path to a background image. Only used when video_path is None. If both are None, a grey background is used.</p> <code>None</code> <code>folder_path</code> <code>str | Path | None</code> <p>Directory where the animation will be saved. If None, nothing is saved. The file format depends on <code>output_format</code>.</p> <code>None</code> <code>tmin</code> <code>int | None</code> <p>Time window in ms. If both None, the whole trial is plotted.</p> <code>None</code> <code>tmax</code> <code>int | None</code> <p>Time window in ms. If both None, the whole trial is plotted.</p> <code>None</code> <code>seconds_to_show</code> <code>float | None</code> <p>Limit the animation to the first N seconds. If None, shows all available data.</p> <code>None</code> <code>scale_factor</code> <code>float</code> <p>Resolution scaling factor (1.0 = original, 0.5 = half resolution).</p> <code>0.5</code> <code>gaze_radius</code> <code>int</code> <p>Radius of the gaze point circle in pixels (before scaling).</p> <code>10</code> <code>gaze_color</code> <code>tuple</code> <p>RGB tuple for gaze point color.</p> <code>(255, 0, 0)</code> <code>fps</code> <code>float | None</code> <p>Frames per second for the animation. If None: - With video: uses the video's native FPS - Without video: defaults to 60 FPS</p> <code>None</code> <code>output_format</code> <code>str</code> <p>Output format for saved animations: - \"html\": Interactive HTML file (default, works in browsers) - \"mp4\": Video file (requires ffmpeg) - \"gif\": Animated GIF file (requires pillow) - \"matplotlib\": Show in matplotlib GUI window (blocking)</p> <code>'matplotlib'</code> <code>display</code> <code>bool</code> <p>If True and output_format is \"html\", returns an HTML object for notebooks. If output_format is \"matplotlib\", this is ignored (always shows window). If False, only saves to file (if folder_path is provided).</p> <code>True</code> <p>Returns:</p> Type Description <code>HTML or None</code> <p>Returns HTML animation if display=True and output_format=\"html\", otherwise None.</p> Source code in <code>pyxations/visualization/visualization.py</code> <pre><code>def plot_animation(\n    self,\n    samples: pl.DataFrame,\n    screen_height: int,\n    screen_width: int,\n    video_path: str | Path | None = None,\n    background_image_path: str | Path | None = None,\n    folder_path: str | Path | None = None,\n    tmin: int | None = None,\n    tmax: int | None = None,\n    seconds_to_show: float | None = None,\n    scale_factor: float = 0.5,\n    gaze_radius: int = 10,\n    gaze_color: tuple = (255, 0, 0),\n    fps: float | None = None,\n    output_format: str = \"matplotlib\",\n    display: bool = True,\n):\n    \"\"\"\n    Create an animated visualization of eye-tracking data.\n\n    When a video is provided, the animation syncs gaze samples with video frames.\n    When no video is provided, gaze points are animated on a grey background or\n    a provided background image, using the sample timestamps for timing.\n\n    Parameters\n    ----------\n    samples\n        Polars DataFrame with gaze samples. Must contain 'tSample' and gaze\n        position columns ('X', 'Y' or 'LX', 'LY', 'RX', 'RY').\n    screen_height, screen_width\n        Stimulus resolution in pixels.\n    video_path\n        Path to a video file. If provided, gaze is overlaid on video frames.\n    background_image_path\n        Path to a background image. Only used when video_path is None.\n        If both are None, a grey background is used.\n    folder_path\n        Directory where the animation will be saved. If None, nothing is saved.\n        The file format depends on `output_format`.\n    tmin, tmax\n        Time window in **ms**. If both None, the whole trial is plotted.\n    seconds_to_show\n        Limit the animation to the first N seconds. If None, shows all available data.\n    scale_factor\n        Resolution scaling factor (1.0 = original, 0.5 = half resolution).\n    gaze_radius\n        Radius of the gaze point circle in pixels (before scaling).\n    gaze_color\n        RGB tuple for gaze point color.\n    fps\n        Frames per second for the animation. If None:\n        - With video: uses the video's native FPS\n        - Without video: defaults to 60 FPS\n    output_format\n        Output format for saved animations:\n        - \"html\": Interactive HTML file (default, works in browsers)\n        - \"mp4\": Video file (requires ffmpeg)\n        - \"gif\": Animated GIF file (requires pillow)\n        - \"matplotlib\": Show in matplotlib GUI window (blocking)\n    display\n        If True and output_format is \"html\", returns an HTML object for notebooks.\n        If output_format is \"matplotlib\", this is ignored (always shows window).\n        If False, only saves to file (if folder_path is provided).\n\n    Returns\n    -------\n    IPython.display.HTML or None\n        Returns HTML animation if display=True and output_format=\"html\", otherwise None.\n    \"\"\"\n    try:\n        import cv2\n        from matplotlib.animation import FuncAnimation\n        import matplotlib as mpl\n        mpl.rcParams['animation.embed_limit'] = 100\n    except ImportError as e:\n        raise ImportError(\n            f\"Missing required dependency for animation: {e}. \"\n            \"Please install cv2 (opencv-python).\"\n        )\n\n    # Validate output_format\n    valid_formats = [\"html\", \"mp4\", \"gif\", \"matplotlib\"]\n    if output_format not in valid_formats:\n        raise ValueError(f\"output_format must be one of {valid_formats}, got '{output_format}'\")\n\n    # ---- Determine gaze columns ----\n    if \"X\" in samples.columns and \"Y\" in samples.columns:\n        x_col, y_col = \"X\", \"Y\"\n    elif \"LX\" in samples.columns and \"LY\" in samples.columns:\n        x_col, y_col = \"LX\", \"LY\"\n    elif \"RX\" in samples.columns and \"RY\" in samples.columns:\n        x_col, y_col = \"RX\", \"RY\"\n    else:\n        raise ValueError(\"Samples DataFrame must contain gaze columns (X, Y) or (LX, LY) or (RX, RY)\")\n\n    # ---- Time filter ----\n    if tmin is not None and tmax is not None:\n        samples = samples.filter(pl.col(\"tSample\").is_between(tmin, tmax))\n\n    if samples.is_empty():\n        raise ValueError(\"No samples available after time filtering\")\n\n    # ---- Drop NaN gaze values ----\n    samples = samples.filter(pl.col(x_col).is_not_null() &amp; pl.col(y_col).is_not_null())\n\n    # ---- Calculate scaled dimensions ----\n    scaled_width = int(screen_width * scale_factor)\n    scaled_height = int(screen_height * scale_factor)\n\n    trial_idx = samples[\"trial_number\"][0] if \"trial_number\" in samples.columns else 0\n\n    # ================= WITH VIDEO =================\n    if video_path is not None:\n        video_path = Path(video_path)\n        if not video_path.exists():\n            raise FileNotFoundError(f\"Video file not found: {video_path}\")\n\n        cap = cv2.VideoCapture(str(video_path))\n        video_fps = cap.get(cv2.CAP_PROP_FPS)\n        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n        video_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n        video_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\n        if fps is None:\n            fps = video_fps\n\n        # Calculate time to frame mapping\n        t_start = samples[\"tSample\"].min()\n        t_end = samples[\"tSample\"].max()\n        trial_duration = t_end - t_start\n\n        # Create frame-to-time mapping\n        frame_edges = np.linspace(t_start, t_end, total_frames + 1)\n        frame_times = ((frame_edges[:-1] + frame_edges[1:]) / 2).astype(int)\n\n        # Build a lookup: frame_index -&gt; list of gaze points\n        samples_np = samples.select([x_col, y_col, \"tSample\"]).to_numpy()\n        gaze_by_frame = {i: [] for i in range(total_frames)}\n\n        for x, y, t in samples_np:\n            # Find the closest frame\n            frame_idx = np.searchsorted(frame_times, t, side='right') - 1\n            frame_idx = max(0, min(frame_idx, total_frames - 1))\n            gaze_by_frame[frame_idx].append((x, y))\n\n        # Limit frames if seconds_to_show is set\n        frames_to_show = total_frames\n        if seconds_to_show is not None:\n            frames_to_show = min(int(fps * seconds_to_show), total_frames)\n\n        # Reset video\n        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n\n        # Create figure\n        fig, ax = plt.subplots(figsize=(10 * scale_factor, 6 * scale_factor))\n        ax.axis('off')\n\n        # Initialize with first frame\n        ret, frame = cap.read()\n        if not ret:\n            cap.release()\n            raise RuntimeError(\"Could not read first frame from video\")\n\n        frame_resized = cv2.resize(frame, (scaled_width, scaled_height), interpolation=cv2.INTER_AREA)\n        frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n        im = ax.imshow(frame_rgb)\n\n        def update_frame_video(frame_idx):\n            ret, frame = cap.read()\n            if not ret:\n                return [im]\n\n            frame_resized = cv2.resize(frame, (scaled_width, scaled_height), interpolation=cv2.INTER_AREA)\n            frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n\n            # Draw gaze points for this frame\n            for gx, gy in gaze_by_frame.get(frame_idx, []):\n                scaled_x = int(gx * scale_factor)\n                scaled_y = int(gy * scale_factor)\n                if 0 &lt;= scaled_x &lt; scaled_width and 0 &lt;= scaled_y &lt; scaled_height:\n                    radius = max(3, int(gaze_radius * scale_factor))\n                    cv2.circle(frame_rgb, (scaled_x, scaled_y), radius=radius, color=gaze_color, thickness=-1)\n\n            im.set_array(frame_rgb)\n            return [im]\n\n        anim = FuncAnimation(fig, update_frame_video, frames=frames_to_show,\n                             interval=1000/fps, blit=True, repeat=True)\n\n    # ================= WITHOUT VIDEO =================\n    else:\n        if fps is None:\n            fps = 60  # Default FPS for sample-based animation\n\n        # Prepare background\n        if background_image_path is not None:\n            bg_path = Path(background_image_path)\n            if not bg_path.exists():\n                raise FileNotFoundError(f\"Background image not found: {bg_path}\")\n            bg_img = mpimg.imread(str(bg_path))\n            if bg_img.dtype == np.float64:\n                bg_img = (bg_img * 255).clip(0, 255).astype(np.uint8)\n            # Resize background to match screen dimensions then scale\n            bg_img = cv2.resize(bg_img, (scaled_width, scaled_height), interpolation=cv2.INTER_AREA)\n        else:\n            # Grey background\n            bg_img = np.ones((scaled_height, scaled_width, 3), dtype=np.uint8) * 128\n\n        # Get time range\n        t_start = samples[\"tSample\"].min()\n        t_end = samples[\"tSample\"].max()\n        trial_duration = t_end - t_start\n\n        # Limit duration if seconds_to_show is set\n        if seconds_to_show is not None:\n            t_end = min(t_end, t_start + int(seconds_to_show * 1000))\n            samples = samples.filter(pl.col(\"tSample\") &lt;= t_end)\n            trial_duration = t_end - t_start\n\n        # Calculate total frames based on duration and fps\n        total_frames = int((trial_duration / 1000) * fps)\n        if total_frames &lt; 1:\n            total_frames = 1\n\n        # Create time bins for each animation frame\n        frame_times = np.linspace(t_start, t_end, total_frames + 1)\n\n        # Build gaze lookup by frame\n        samples_np = samples.select([x_col, y_col, \"tSample\"]).to_numpy()\n        gaze_by_frame = {i: [] for i in range(total_frames)}\n\n        for x, y, t in samples_np:\n            frame_idx = np.searchsorted(frame_times, t, side='right') - 1\n            frame_idx = max(0, min(frame_idx, total_frames - 1))\n            gaze_by_frame[frame_idx].append((x, y))\n\n        # Create figure\n        fig, ax = plt.subplots(figsize=(10 * scale_factor, 6 * scale_factor))\n        ax.axis('off')\n\n        # Initialize with background\n        im = ax.imshow(bg_img.copy())\n\n        def update_frame_no_video(frame_idx):\n            # Start with fresh background copy\n            frame_rgb = bg_img.copy()\n\n            # Draw gaze points for this frame\n            for gx, gy in gaze_by_frame.get(frame_idx, []):\n                scaled_x = int(gx * scale_factor)\n                scaled_y = int(gy * scale_factor)\n                if 0 &lt;= scaled_x &lt; scaled_width and 0 &lt;= scaled_y &lt; scaled_height:\n                    radius = max(3, int(gaze_radius * scale_factor))\n                    cv2.circle(frame_rgb, (scaled_x, scaled_y), radius=radius, color=gaze_color, thickness=-1)\n\n            im.set_array(frame_rgb)\n            return [im]\n\n        anim = FuncAnimation(fig, update_frame_no_video, frames=total_frames,\n                             interval=1000/fps, blit=True, repeat=True)\n\n    # ================= SAVE / DISPLAY =================\n    result = None\n    trial_idx_val = trial_idx\n\n    # Build output filename\n    anim_name = f\"animation_{trial_idx_val}\"\n    if tmin is not None and tmax is not None:\n        anim_name += f\"_{tmin}_{tmax}\"\n\n    # Handle different output formats\n    if output_format == \"matplotlib\":\n        # Show in matplotlib GUI window (blocking)\n        plt.show()\n        # Cleanup video capture if used\n        if video_path is not None:\n            cap.release()\n        return None\n\n    elif output_format == \"mp4\":\n        if folder_path:\n            folder_path = Path(folder_path)\n            folder_path.mkdir(parents=True, exist_ok=True)\n            out_path = folder_path / f\"{anim_name}.mp4\"\n            try:\n                anim.save(str(out_path), writer='ffmpeg', fps=fps)\n                print(f\"Animation saved to: {out_path}\")\n            except Exception as e:\n                raise RuntimeError(\n                    f\"Failed to save MP4. Make sure ffmpeg is installed. Error: {e}\"\n                )\n        plt.close(fig)\n\n    elif output_format == \"gif\":\n        if folder_path:\n            folder_path = Path(folder_path)\n            folder_path.mkdir(parents=True, exist_ok=True)\n            out_path = folder_path / f\"{anim_name}.gif\"\n            try:\n                anim.save(str(out_path), writer='pillow', fps=fps)\n                print(f\"Animation saved to: {out_path}\")\n            except Exception as e:\n                raise RuntimeError(\n                    f\"Failed to save GIF. Make sure pillow is installed. Error: {e}\"\n                )\n        plt.close(fig)\n\n    else:  # html (default)\n        if folder_path:\n            folder_path = Path(folder_path)\n            folder_path.mkdir(parents=True, exist_ok=True)\n            out_path = folder_path / f\"{anim_name}.html\"\n            with open(out_path, 'w') as f:\n                f.write(anim.to_jshtml())\n            print(f\"Animation saved to: {out_path}\")\n\n        if display:\n            try:\n                from IPython.display import HTML\n                plt.close(fig)\n                result = HTML(anim.to_jshtml())\n            except ImportError:\n                print(\"IPython not available. Use output_format='matplotlib' for GUI display.\")\n                plt.close(fig)\n        else:\n            plt.close(fig)\n\n    # Cleanup video capture if used\n    if video_path is not None:\n        cap.release()\n\n    return result\n</code></pre>"},{"location":"api_reference/#pyxations.visualization.visualization.Visualization.plot_multipanel","title":"<code>plot_multipanel(fixations, saccades, display=True)</code>","text":"<p>Create a 2\u00d72 multi\u2011panel diagnostic plot for every non\u2011empty phase label and save it as PNG in //plots/. Source code in <code>pyxations/visualization/visualization.py</code> <pre><code>def plot_multipanel(\n        self,\n        fixations: pl.DataFrame,\n        saccades: pl.DataFrame,\n        display: bool = True\n    ) -&gt; None:\n    \"\"\"\n    Create a 2\u00d72 multi\u2011panel diagnostic plot for every non\u2011empty\n    phase label and save it as PNG in\n    &lt;derivatives_folder_path&gt;/&lt;events_detection_folder&gt;/plots/.\n    \"\"\"\n    # \u2500\u2500 paths &amp; matplotlib style \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    folder_path: Path = (\n        self.derivatives_folder_path\n        / self.events_detection_folder\n        / \"plots\"\n    )\n    folder_path.mkdir(parents=True, exist_ok=True)\n    plt.rcParams.update({\"font.size\": 12})\n\n    # \u2500\u2500 drop practice / invalid trials \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    fixations = fixations.filter(pl.col(\"trial_number\") != -1)\n    saccades  = saccades.filter(pl.col(\"trial_number\") != -1)\n\n    # \u2500\u2500 collect valid phase labels (skip empty string) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    phases = (\n        fixations\n        .select(pl.col(\"phase\").filter(pl.col(\"phase\") != \"\"))\n        .unique()           # unique values in this Series\n        .to_series()\n        .to_list()          # plain Python list of strings\n    )\n\n    # \u2500\u2500 one figure per phase \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    for phase in phases:\n        fix_phase   = fixations.filter(pl.col(\"phase\") == phase)\n        sacc_phase  = saccades.filter(pl.col(\"phase\") == phase)\n\n        fig, axs = plt.subplots(2, 2, figsize=(12, 7))\n\n        self.fix_duration(fix_phase , axs=axs[0, 0])\n        self.sacc_main_sequence(sacc_phase, axs=axs[1, 1])\n        self.sacc_direction(sacc_phase, axs=axs[1, 0], figs=fig)\n        self.sacc_amplitude(sacc_phase, axs=axs[0, 1])\n\n        fig.tight_layout()\n        plt.savefig(folder_path / f\"multipanel_{phase}.png\")\n        if display:\n            plt.show()\n        plt.close()\n</code></pre>"},{"location":"api_reference/#pyxations.visualization.visualization.Visualization.scanpath","title":"<code>scanpath(fixations, screen_height, screen_width, folder_path=None, tmin=None, tmax=None, saccades=None, samples=None, phase_data=None, display=True)</code>","text":"<p>Fast scan\u2011path visualiser.</p> <p>\u2022 Vectorised: no per\u2011row Python loops \u2022 Single pass phase grouping \u2022 Uses <code>BrokenBarHCollection</code> for fixation spans \u2022 Optional asynchronous PNG write via ThreadPoolExecutor (drop\u2011in\u2011ready, see comment)</p> <p>Parameters:</p> Name Type Description Default <code>fixations</code> <code>DataFrame</code> <p>Polars DataFrame with at least <code>tStart</code>, <code>duration</code>, <code>xAvg</code>, <code>yAvg</code>, <code>phase</code>.</p> required <code>screen_height</code> <code>int</code> <p>Stimulus resolution in pixels.</p> required <code>screen_width</code> <code>int</code> <p>Stimulus resolution in pixels.</p> required <code>folder_path</code> <code>str | Path | None</code> <p>Directory where 1 PNG per phase will be stored.  If None, nothing is saved.</p> <code>None</code> <code>tmin</code> <code>int | None</code> <p>Time window in ms.  If both <code>None</code>, the whole trial is plotted.</p> <code>None</code> <code>tmax</code> <code>int | None</code> <p>Time window in ms.  If both <code>None</code>, the whole trial is plotted.</p> <code>None</code> <code>saccades</code> <code>DataFrame | None</code> <p>Polars DataFrame with <code>tStart</code>, <code>phase</code>, \u2026  (optional).</p> <code>None</code> <code>samples</code> <code>DataFrame | None</code> <p>Polars DataFrame with gaze traces (<code>tSample</code>, <code>LX</code>, <code>LY</code>, <code>RX</code>, <code>RY</code> or <code>X</code>, <code>Y</code>) (optional).</p> <code>None</code> <code>phase_data</code> <code>dict[str, dict] | None</code> <p>Per\u2011phase extras::</p> <pre><code>{\n    \"search\": {\n        \"img_paths\": [...],\n        \"img_plot_coords\": [(x1,y1,x2,y2), ...],\n        \"bbox\": (x1,y1,x2,y2),\n    },\n    ...\n}\n</code></pre> <code>None</code> <code>display</code> <code>bool</code> <p>If False the figure canvas is never shown (faster for batch jobs).</p> <code>True</code> Source code in <code>pyxations/visualization/visualization.py</code> <pre><code>def scanpath(\n    self,\n    fixations: pl.DataFrame,\n    screen_height: int,\n    screen_width: int,\n    folder_path: str | Path | None = None,\n    tmin: int | None = None,\n    tmax: int | None = None,\n    saccades: pl.DataFrame | None = None,\n    samples: pl.DataFrame | None = None,\n    phase_data: dict[str, dict] | None = None,\n    display: bool = True,\n):\n    \"\"\"\n    Fast scan\u2011path visualiser.\n\n    \u2022 **Vectorised**: no per\u2011row Python loops  \n    \u2022 **Single pass** phase grouping  \n    \u2022 Uses `BrokenBarHCollection` for fixation spans  \n    \u2022 Optional asynchronous PNG write via ThreadPoolExecutor (drop\u2011in\u2011ready, see comment)\n\n    Parameters\n    ----------\n    fixations\n        Polars DataFrame with at least `tStart`, `duration`, `xAvg`, `yAvg`, `phase`.\n    screen_height, screen_width\n        Stimulus resolution in pixels.\n    folder_path\n        Directory where 1 PNG per phase will be stored.  If *None*, nothing is saved.\n    tmin, tmax\n        Time window in **ms**.  If both `None`, the whole trial is plotted.\n    saccades\n        Polars DataFrame with `tStart`, `phase`, \u2026  (optional).\n    samples\n        Polars DataFrame with gaze traces (`tSample`, `LX`, `LY`, `RX`, `RY` or\n        `X`, `Y`) (optional).\n    phase_data\n        Per\u2011phase extras::\n\n            {\n                \"search\": {\n                    \"img_paths\": [...],\n                    \"img_plot_coords\": [(x1,y1,x2,y2), ...],\n                    \"bbox\": (x1,y1,x2,y2),\n                },\n                ...\n            }\n\n    display\n        If *False* the figure canvas is never shown (faster for batch jobs).\n    \"\"\"\n\n\n    # ------------- small helpers ------------------------------------------------\n    def _make_axes(plot_samples: bool):\n        if plot_samples:\n            fig, (ax_main, ax_gaze) = plt.subplots(\n                2, 1, height_ratios=(4, 1), figsize=(10, 6), sharex=False\n            )\n        else:\n            fig, ax_main = plt.subplots(figsize=(10, 6))\n            ax_gaze = None\n        ax_main.set_xlim(0, screen_width)\n        ax_main.set_ylim(screen_height, 0)\n        return fig, ax_main, ax_gaze\n\n    def _maybe_cache_img(path):\n        \"\"\"Load image from disk with a small LRU cache.\"\"\"\n\n        # Cache hit: move to the end (most recently used)\n        if path in _img_cache:\n            img = _img_cache.pop(path)\n            _img_cache[path] = img\n            return img\n\n        # Cache miss: load image\n        img = mpimg.imread(path)\n\n        # Optional: reduce memory if image is float64 in [0, 1]\n        if isinstance(img, np.ndarray) and img.dtype == np.float64:\n            img = (img * 255).clip(0, 255).astype(np.uint8)\n\n        # Insert into cache\n        _img_cache[path] = img\n\n        # If cache too big, drop least recently used item\n        if len(_img_cache) &gt; _MAX_CACHE_ITEMS:\n            _img_cache.popitem(last=False)  # pops the oldest inserted item\n\n        return img\n\n    # ---------------------------------------------------------------------------\n    plot_saccades = saccades is not None\n    plot_samples = samples is not None\n    _img_cache = OrderedDict()\n    _MAX_CACHE_ITEMS = 8  # or 5, 10, etc. Tune as you like.\n\n    trial_idx = fixations[\"trial_number\"][0]\n\n    # ---- time filter ----------------------------------------------------------\n    if tmin is not None and tmax is not None:\n        fixations = fixations.filter(pl.col(\"tStart\").is_between(tmin, tmax))\n        if plot_saccades:\n            saccades = saccades.filter(pl.col(\"tStart\").is_between(tmin, tmax))\n        if plot_samples:\n            samples = samples.filter(pl.col(\"tSample\").is_between(tmin, tmax))\n\n    # remove empty phase markings\n    fixations = fixations.filter(pl.col(\"phase\") != \"\")\n    if plot_saccades:\n        saccades = saccades.filter(pl.col(\"phase\") != \"\")\n    if plot_samples:\n        samples = samples.filter(pl.col(\"phase\") != \"\")\n\n    # ---- split once by phase --------------------------------------------------\n    fix_by_phase = fixations.partition_by(\"phase\", as_dict=True)\n    sac_by_phase = (\n        saccades.partition_by(\"phase\", as_dict=True) if plot_saccades else {}\n    )\n    samp_by_phase = (\n        samples.partition_by(\"phase\", as_dict=True) if plot_samples else {}\n    )\n\n    # colour map shared across phases\n    cmap = plt.cm.rainbow\n\n    # ---- build &amp; draw ---------------------------------------------------------\n    # optional async saver (uncomment if you save hundreds of files)\n    from concurrent.futures import ThreadPoolExecutor\n    saver = ThreadPoolExecutor(max_workers=4) if folder_path else None\n\n    if not display:\n        plt.ioff()\n\n    for phase, phase_fix in fix_by_phase.items():\n        if phase_fix.is_empty():\n            continue\n\n        # ---------- vectors (zero\u2011copy) -----------------\n        fx, fy, fdur = phase_fix.select([\"xAvg\", \"yAvg\", \"duration\"]).to_numpy().T\n        n_fix = fx.size\n        fix_idx = np.arange(1, n_fix + 1)\n\n        norm = mplcolors.BoundaryNorm(np.arange(1, n_fix + 2), cmap.N)\n\n        # saccades\n        sac_t = (\n            sac_by_phase[phase][\"tStart\"].to_numpy()\n            if plot_saccades and phase in sac_by_phase\n            else np.empty(0)\n        )\n\n        # samples\n        if plot_samples and phase in samp_by_phase and samp_by_phase[phase].height:\n            samp_phase = samp_by_phase[phase]\n            t0 = samp_phase[\"tSample\"][0]\n            ts = (samp_phase[\"tSample\"].to_numpy() - t0) \n            get = samp_phase.get_column\n            lx = get(\"LX\").to_numpy() if \"LX\" in samp_phase.columns else None\n            ly = get(\"LY\").to_numpy() if \"LY\" in samp_phase.columns else None\n            rx = get(\"RX\").to_numpy() if \"RX\" in samp_phase.columns else None\n            ry = get(\"RY\").to_numpy() if \"RY\" in samp_phase.columns else None\n            gx = get(\"X\").to_numpy() if \"X\" in samp_phase.columns else None\n            gy = get(\"Y\").to_numpy() if \"Y\" in samp_phase.columns else None\n        else:\n            t0 = None\n\n        # ---------- figure -----------------------------\n        fig, ax_main, ax_gaze = _make_axes(plot_samples and t0 is not None)\n        # scatter fixations\n        sc = ax_main.scatter(\n            fx,\n            fy,\n            c=fix_idx,\n            s=fdur,\n            cmap=cmap,\n            norm=norm,\n            alpha=0.5,\n            zorder=2,\n        )\n        fig.colorbar(\n            sc,\n            ax=ax_main,\n            ticks=[1, n_fix // 2 if n_fix &gt; 2 else n_fix, n_fix],\n            fraction=0.046,\n            pad=0.04,\n        ).set_label(\"# of fixation\")\n\n        # ---------- stimulus imagery / bbox ------------\n        if phase_data and phase[0] in phase_data:\n            pdict = phase_data[phase[0]]\n            coords = pdict.get(\"img_plot_coords\") or []\n            bbox = pdict.get('bbox',None) \n            for img_path, box in zip(pdict.get(\"img_paths\", []), coords):\n\n                ax_main.imshow(_maybe_cache_img(img_path), extent=[box[0], box[2], box[3], box[1]], zorder=0)\n            if bbox is not None:\n                x1, y1, x2, y2 = bbox\n                ax_main.plot([x1, x2, x2, x1, x1], [y1, y1, y2, y2, y1], color='red', linewidth=1.5, zorder=3)\n\n        # ---------- gaze traces ------------------------\n        if ax_gaze is not None:\n            if lx is not None:\n                ax_main.plot(lx, ly, \"--\", color=\"C0\", zorder=1)\n                ax_gaze.plot(ts, lx, label=\"Left\u202fX\")\n                ax_gaze.plot(ts, ly, label=\"Left\u202fY\")\n            if rx is not None:\n                ax_main.plot(rx, ry, \"--\", color=\"k\", zorder=1)\n                ax_gaze.plot(ts, rx, label=\"Right\u202fX\")\n                ax_gaze.plot(ts, ry, label=\"Right\u202fY\")\n            if gx is not None:\n                ax_main.plot(gx, gy, \"--\", color=\"k\", zorder=1, alpha=0.6)\n                ax_gaze.plot(ts, gx, label=\"X\")\n                ax_gaze.plot(ts, gy, label=\"Y\")\n\n            # fixation spans\n            bars   = np.c_[phase_fix['tStart'].to_numpy() - t0,\n                        phase_fix['duration'].to_numpy()]\n            height = ax_gaze.get_ylim()[1] - ax_gaze.get_ylim()[0]\n            colors = cmap(norm(fix_idx))\n\n            # Draw all bars in one call; no BrokenBarHCollection import needed\n            ax_gaze.broken_barh(bars, (0, height), facecolors=colors, alpha=0.4)\n            # saccades\n            if sac_t.size:\n                ymin, ymax = ax_gaze.get_ylim()\n                ax_gaze.vlines(\n                    sac_t - t0,\n                    ymin,\n                    ymax,\n                    colors=\"red\",\n                    linestyles=\"--\",\n                    linewidth=0.8,\n                )\n\n            # tidy gaze axis\n            h, l = ax_gaze.get_legend_handles_labels()\n            by_label = {lab: hdl for hdl, lab in zip(h, l)}\n            ax_gaze.legend(\n                by_label.values(),\n                by_label.keys(),\n                loc=\"center left\",\n                bbox_to_anchor=(1, 0.5),\n            )\n            ax_gaze.set_ylabel(\"Gaze\")\n            ax_gaze.set_xlabel(\"Time [s]\")\n\n        fig.tight_layout()\n\n        # ---------- save / show ------------------------\n        if folder_path:\n            scan_name = f\"scanpath_{trial_idx}\"\n            if tmin is not None and tmax is not None:\n                scan_name += f\"_{tmin}_{tmax}\"\n            out = Path(folder_path) / f\"{scan_name}_{phase[0]}.png\"\n            fig.savefig(out, dpi=150)\n            if saver:  saver.submit(fig.savefig, out, dpi=150)\n\n        if display:\n            plt.show()\n        plt.close(fig)\n\n    if not display:\n        plt.ion()\n</code></pre>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are welcome! Please check out the issues and submit a pull request if you'd like to help.</p>"},{"location":"contributing/#to-develop-locally","title":"To develop locally","text":"<pre><code># Clone repository\ngit clone https://github.com/NeuroLIAA/pyxations.git\ncd pyxations\n\n# Create virtual environment and install\nuv venv\nuv pip install -e '.[dev]'\n\n# To work on documentation\nuv pip install -e '.[docs]'\n</code></pre>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#installation","title":"Installation","text":"<p>You can install Pyxations using <code>uv</code> (recommended for modern workflows):</p> <pre><code>uv pip install pyxations\n</code></pre> <p>Or directly with <code>pip</code>:</p> <pre><code>pip install pyxations\n</code></pre>"},{"location":"license/","title":"License","text":"<p>MIT License</p> <p>Copyright (c) [2025][Pyxations]</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"requirements/","title":"Requirements","text":"<ul> <li><code>Python 3.10</code> or newer is required.</li> <li>The <code>edf2asc</code> software from EyeLink is required for converting EDF files to ASCII format. Please ensure that the EyeLink software is installed and accessible in your system's PATH. The program is provided with the latest version of the EyeLink Developers Kit.</li> </ul>"},{"location":"requirements/#dependencies","title":"Dependencies","text":"<p>Pyxations relies on several scientific computing and visualization libraries, including:</p> <ul> <li><code>numpy</code></li> <li><code>pandas</code></li> <li><code>matplotlib</code></li> <li><code>seaborn</code></li> <li><code>scipy</code></li> <li><code>statsmodels</code></li> <li><code>pyarrow</code></li> <li><code>remodnav</code></li> <li><code>multimatch-gaze</code></li> </ul> <p>The full list of dependencies is specified in <code>pyproject.toml</code>.</p>"},{"location":"usage/","title":"Usage","text":""},{"location":"usage/#minimal-example","title":"Minimal Example","text":"<pre><code>import pyxations as pyx\n\n# 1) Convert raw files to BIDS\npyx.dataset_to_bids(\n    target_folder_path=\" Path/to/the/folder/where/the/BIDS/dataset/will/be/created\", \n    files_folder_path=\"Path/to/the/folder/containing/the/EDF/files\",  \n    dataset_name=\"dataset_name\",\n)\n\n# 2) Compute derivatives using REMoDNaV\nmsg_keywords = [\"begin\", \"end\", \"press\"]\nstart_msgs   = {\"search\": [\"beginning_of_stimuli\"]}\nend_msgs     = {\"search\": [\"end_of_stimuli\"]}\n\npyx.compute_derivatives_for_dataset(\n    bids_path,\n    dataset_format=\"eyelink\",\n    detection_algorithm=\"remodnav\",\n    msg_keywords=msg_keywords,\n    start_msgs=start_msgs,\n    end_msgs=end_msgs,\n    overwrite=True,\n)\n</code></pre>"}]}