{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_besteye(df_msg, default='R'):\n",
    "    val_msgs = (df_msg[df_msg['text'].str.contains('CAL VALIDATION')][-2:]).to_numpy(dtype=str)\n",
    "    if not len(val_msgs) or 'ABORTED' in val_msgs[0][1]:\n",
    "        return default\n",
    "\n",
    "    left_index = int('LEFT' in val_msgs[1][1])\n",
    "    right_index = 1 - left_index\n",
    "    lefterror_index, righterror_index = val_msgs[left_index][1].split().index('ERROR'), val_msgs[right_index][\n",
    "        1].split().index('ERROR')\n",
    "    left_error = float(val_msgs[left_index][1].split()[lefterror_index + 1])\n",
    "    right_error = float(val_msgs[right_index][1].split()[righterror_index + 1])\n",
    "\n",
    "    return 'L' if left_error < right_error else 'R'\n",
    "\n",
    "\n",
    "def filter_msgs(df_msg, cutout='validation'):\n",
    "    first_index = df_msg.index[df_msg['text'].str.contains(cutout)].tolist()[0]\n",
    "\n",
    "    return df_msg[first_index:]\n",
    "\n",
    "\n",
    "def is_binocular(df_fix):\n",
    "    return len(df_fix['eye'].unique()) > 1\n",
    "\n",
    "\n",
    "def keep_besteye(df_fix, df_msg, default='R'):\n",
    "    best_eye = default\n",
    "    if is_binocular(df_fix):\n",
    "        best_eye = find_besteye(df_msg, default)\n",
    "        df_fix = df_fix[df_fix['eye'] == best_eye]\n",
    "\n",
    "    return df_fix, best_eye\n",
    "\n",
    "\n",
    "def extract_calpoints(df_msg, best_eye, legend='Calibration points', npoints=9):\n",
    "    calpoints_msg = df_msg[df_msg['text'].str.contains(legend)]\n",
    "    calpoints = []\n",
    "    if not calpoints_msg.empty:\n",
    "        if len(calpoints_msg) >= 2:\n",
    "            calpoints_msgidx = calpoints_msg.iloc[-2].name if best_eye == 'L' else calpoints_msg.iloc[-1].name\n",
    "        else:\n",
    "            calpoints_msgidx = calpoints_msg.iloc[0].name\n",
    "        calpoints = df_msg.loc[calpoints_msgidx + 1:calpoints_msgidx + npoints]['text'].to_numpy()\n",
    "        calpoints = [list(map(lambda x: float(x.replace(',', '')), msg.split()[1:3])) for msg in calpoints]\n",
    "    calpoints = pd.DataFrame(calpoints, columns=['x', 'y'])\n",
    "\n",
    "    return calpoints\n",
    "\n",
    "\n",
    "def extract_valpoints(df_msg, best_eye, legend='VALIDATE', npoints=9):\n",
    "    valpoints_msg = df_msg[df_msg['text'].str.contains(legend)]\n",
    "    if len(valpoints_msg) > npoints:\n",
    "        besteye_legend = 'RIGHT' if best_eye == 'R' else 'LEFT'\n",
    "        valpoints_msg = valpoints_msg[valpoints_msg['text'].str.contains(besteye_legend)]\n",
    "    valpoints_msg = valpoints_msg['text'].to_numpy()\n",
    "    points = [msg.split('at')[1].split('OFFSET')[0].split(',') for msg in valpoints_msg]\n",
    "    regexp = r'(-?\\d+\\.\\d+)\\s*,\\s*(-?\\d+\\.\\d+)\\s*pix'\n",
    "    offsets = [re.findall(regexp, msg.split('at')[1].split('OFFSET')[1]) for msg in valpoints_msg]\n",
    "    offsets = [(float(offset[0][0]), float(offset[0][1])) for offset in offsets]\n",
    "    points = [(int(point[0]), int(point[1])) for point in points]\n",
    "    valpoints = pd.DataFrame(points, columns=['x', 'y']).astype(int)\n",
    "    valoffsets = pd.DataFrame(offsets, columns=['x', 'y']).astype(float)\n",
    "\n",
    "    return valpoints, valoffsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def convert_edf_to_ascii(edf_file_path, output_dir=None):\n",
    "    \"\"\"\n",
    "    Convert an EDF file to ASCII format using edf2asc.\n",
    "\n",
    "    Args:\n",
    "        edf_file_path (str): Path to the input EDF file.\n",
    "        output_dir (str): Directory to save the ASCII file. If None, the ASCII file will be saved in the same directory as the input EDF file.\n",
    "\n",
    "    Returns:\n",
    "        str: Path to the generated ASCII file.\n",
    "    \"\"\"\n",
    "    # Check if edf2asc is installed\n",
    "    if not shutil.which(\"edf2asc\"):\n",
    "        raise FileNotFoundError(\"edf2asc not found. Please make sure EyeLink software is installed and accessible in the system PATH.\")\n",
    "\n",
    "    # Set output directory\n",
    "    if output_dir is None:\n",
    "        output_dir = os.path.dirname(edf_file_path)\n",
    "\n",
    "    # Generate output file path\n",
    "    edf_file_name = os.path.basename(edf_file_path)\n",
    "    ascii_file_name = os.path.splitext(edf_file_name)[0] + \".asc\"\n",
    "    ascii_file_path = os.path.join(output_dir, ascii_file_name)\n",
    "\n",
    "    # Run edf2asc command with the -f flag, only run it if the file does not already exist\n",
    "    if not os.path.exists(ascii_file_path):\n",
    "        subprocess.run([\"edf2asc\", \"-f\", edf_file_path, ascii_file_path])\n",
    "\n",
    "    return ascii_file_path\n",
    "\n",
    "\n",
    "\n",
    "def parse_edf_eyelink(edf_file_path, msg_keywords):\n",
    "    \"\"\"\n",
    "    Parse an EDF file generated by EyeLink system.\n",
    "\n",
    "    Args:\n",
    "        edf_file_path (str): Path to the input EDF file.\n",
    "        msg_keywords (list of str): List of strings representing keywords to filter MSG lines.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing five pandas DataFrames:\n",
    "            - Header information DataFrame\n",
    "            - MSG lines DataFrame filtered by msg_keywords\n",
    "            - Calibration information DataFrame\n",
    "            - EyeLink events DataFrame\n",
    "            - Raw sample data DataFrame\n",
    "    \"\"\"\n",
    "    # Convert EDF to ASCII\n",
    "    ascii_file_path = convert_edf_to_ascii(edf_file_path)\n",
    "\n",
    "    # ===== READ IN FILES ===== #\n",
    "    # Read in EyeLink file\n",
    "    \n",
    "    f = open(ascii_file_path,'r')\n",
    "    fileTxt0 = f.read().splitlines(True) # split into lines\n",
    "    fileTxt0 = list(filter(None, fileTxt0)) #  remove emptys\n",
    "    fileTxt0 = np.array(fileTxt0) # concert to np array for simpler indexing\n",
    "    f.close()\n",
    "\n",
    "\n",
    "    # Separate lines into samples and messages\n",
    "    print('Sorting lines...')\n",
    "    nLines = len(fileTxt0)\n",
    "    lineType = np.array(['OTHER']*nLines,dtype='object')\n",
    "\n",
    "\n",
    "    # Usar lo de mne, particularmente para calibration.\n",
    "    # En sample tendría que filtrar lo que viene después de START y antes de END.\n",
    "    \n",
    "\n",
    "    calibration_flag = False\n",
    "    start_flag = False\n",
    "    for iLine in range(nLines):\n",
    "        if len(fileTxt0[iLine])<3:\n",
    "            lineType[iLine] = 'EMPTY'\n",
    "        elif fileTxt0[iLine].startswith('*'):\n",
    "            lineType[iLine] = 'HEADER'\n",
    "        # If there is a !CAL in the line, it is a calibration line\n",
    "        elif '!CAL' in fileTxt0[iLine]:\n",
    "            lineType[iLine] = 'Calibration'\n",
    "            calibration_flag = True\n",
    "        elif fileTxt0[iLine].split()[0] == 'START' and calibration_flag:\n",
    "            calibration_flag = False\n",
    "            start_flag = True\n",
    "        elif calibration_flag:\n",
    "            lineType[iLine] = 'Calibration'\n",
    "        elif not start_flag:\n",
    "            lineType[iLine] = 'EMPTY'\n",
    "        elif fileTxt0[iLine].split()[0] == 'MSG' and any(keyword in fileTxt0[iLine] for keyword in msg_keywords):\n",
    "            lineType[iLine] = 'MSG'\n",
    "        elif fileTxt0[iLine].split()[0][0].isdigit() or fileTxt0[iLine].split()[0].startswith('-'):\n",
    "            lineType[iLine] = 'SAMPLE'\n",
    "        else:\n",
    "            lineType[iLine] = fileTxt0[iLine].split()[0]\n",
    "        \n",
    "    # Print the amount of each type of line\n",
    "    print('Amount of each line type:')\n",
    "    print(pd.Series(lineType).value_counts())\n",
    "    \n",
    "    \n",
    "    # ===== PARSE EYELINK FILE ===== #\n",
    "    # Import Header\n",
    "    print('Parsing header...')\n",
    "    dfHeader = pd.read_csv(ascii_file_path,skiprows=np.nonzero(lineType!='HEADER')[0],header=None,sep='\\s+')\n",
    "    # Merge columns into single strings\n",
    "    dfHeader = dfHeader.apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1)\n",
    "\n",
    "\n",
    "    # Import Calibration\n",
    "    print('Parsing calibration...')\n",
    "    iCal = np.nonzero(lineType=='Calibration')[0]\n",
    "    dfCalib = pd.read_csv(ascii_file_path,skiprows=iCal,header=None)\n",
    "\n",
    "\n",
    "\n",
    "    # Import Message\n",
    "    print('Parsing messages...')\n",
    "    i_msg = np.nonzero(lineType == 'MSG')[0]\n",
    "    t_msg = []\n",
    "    txt_msg = []\n",
    "    for i in range(len(i_msg)):\n",
    "        # separate MSG prefix and timestamp from rest of message\n",
    "        info = fileTxt0[i_msg[i]].split()\n",
    "        # extract info\n",
    "        t_msg.append(int(info[1]))\n",
    "        txt_msg.append(' '.join(info[2:]))\n",
    "    dfMsg = pd.DataFrame({'time': t_msg, 'text': txt_msg})\n",
    "\n",
    "    # Import Fixations\n",
    "    print('Parsing fixations...')\n",
    "    i_not_efix = np.nonzero(lineType != 'EFIX')[0]\n",
    "    df_fix = pd.read_csv(ascii_file_path, skiprows=i_not_efix, header=None, delim_whitespace=True, usecols=range(1, 8),\n",
    "                         low_memory=False)\n",
    "    df_fix.columns = ['eye', 'tStart', 'tEnd', 'duration', 'xAvg', 'yAvg', 'pupilAvg']\n",
    "\n",
    "    # Saccades\n",
    "    print('Parsing saccades...')\n",
    "    i_not_esacc = np.nonzero(lineType != 'ESACC')[0]\n",
    "    df_sacc = pd.read_csv(ascii_file_path, skiprows=i_not_esacc, header=None, delim_whitespace=True, usecols=range(1, 11),\n",
    "                          low_memory=False)\n",
    "    df_sacc.columns = ['eye', 'tStart', 'tEnd', 'duration', 'xStart', 'yStart', 'xEnd', 'yEnd', 'ampDeg', 'vPeak']\n",
    "\n",
    "    # Blinks\n",
    "    print('Parsing blinks...')\n",
    "    df_blink = pd.DataFrame()\n",
    "    i_not_eblink = np.nonzero(lineType != 'EBLINK')[0]\n",
    "    if len(i_not_eblink) < nLines:\n",
    "        df_blink = pd.read_csv(ascii_file_path, skiprows=i_not_eblink, header=None, delim_whitespace=True, usecols=range(1, 5),\n",
    "                               low_memory=False)\n",
    "        df_blink.columns = ['eye', 'tStart', 'tEnd', 'duration']\n",
    "\n",
    "    # determine sample columns based on eyes recorded in file\n",
    "    eyes_in_file = np.unique(df_fix.eye)\n",
    "    if eyes_in_file.size == 2:\n",
    "        cols = ['tSample', 'LX', 'LY', 'LPupil', 'RX', 'RY', 'RPupil']\n",
    "    else:\n",
    "        eye = eyes_in_file[0]\n",
    "        print('monocular data detected (%c eye).' % eye)\n",
    "        cols = ['tSample', '%cX' % eye, '%cY' % eye, '%cPupil' % eye]\n",
    "\n",
    "    # Import samples\n",
    "    i_not_sample = np.nonzero(lineType != 'SAMPLE')[0]\n",
    "    dfSamples = pd.read_csv(ascii_file_path, skiprows=i_not_sample, header=None, delim_whitespace=True,\n",
    "                                usecols=range(0, len(cols)), low_memory=False)\n",
    "    dfSamples.columns = cols\n",
    "    # Convert values to numbers\n",
    "    for eye in ['L', 'R']:\n",
    "        if eye in eyes_in_file:\n",
    "            dfSamples['%cX' % eye] = pd.to_numeric(dfSamples['%cX' % eye], errors='coerce')\n",
    "            dfSamples['%cY' % eye] = pd.to_numeric(dfSamples['%cY' % eye], errors='coerce')\n",
    "            dfSamples['%cPupil' % eye] = pd.to_numeric(dfSamples['%cPupil' % eye], errors='coerce')\n",
    "        else:\n",
    "            dfSamples['%cX' % eye] = np.nan\n",
    "            dfSamples['%cY' % eye] = np.nan\n",
    "            dfSamples['%cPupil' % eye] = np.nan\n",
    "\n",
    "    dict_events = {'fix': df_fix, 'sacc': df_sacc, 'blink': df_blink}\n",
    "    return dfHeader, dfMsg, dfCalib, dfSamples, dict_events\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting lines...\n",
      "Amount of each line type:\n",
      "SAMPLE         828742\n",
      "SFIX             4323\n",
      "EFIX             4317\n",
      "ESACC            4181\n",
      "SSACC            4181\n",
      "MSG              1388\n",
      "EBLINK            587\n",
      "SBLINK            585\n",
      "Calibration       549\n",
      "END                95\n",
      "PRESCALER          95\n",
      "VPRESCALER         95\n",
      "PUPIL              95\n",
      "EVENTS             95\n",
      "SAMPLES            95\n",
      "START              90\n",
      "EMPTY              61\n",
      "HEADER             10\n",
      "OTHER               5\n",
      "Name: count, dtype: int64\n",
      "Parsing header...\n",
      "Parsing calibration...\n",
      "Parsing messages...\n",
      "Parsing fixations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15255/3259038764.py:133: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df_fix = pd.read_csv(ascii_file_path, skiprows=i_not_efix, header=None, delim_whitespace=True, usecols=range(1, 8),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing saccades...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15255/3259038764.py:140: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df_sacc = pd.read_csv(ascii_file_path, skiprows=i_not_esacc, header=None, delim_whitespace=True, usecols=range(1, 11),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing blinks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15255/3259038764.py:149: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df_blink = pd.read_csv(ascii_file_path, skiprows=i_not_eblink, header=None, delim_whitespace=True, usecols=range(1, 5),\n",
      "/tmp/ipykernel_15255/3259038764.py:164: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  dfSamples = pd.read_csv(ascii_file_path, skiprows=i_not_sample, header=None, delim_whitespace=True,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header DataFrame:\n",
      "0    ** CONVERTED FROM ab01_second_half_2023-10-09_...\n",
      "1                    ** DATE: Sun Jun 29 00:37:35 2003\n",
      "2         ** TYPE: EDF_FILE BINARY EVENT SAMPLE TAGGED\n",
      "3                             ** VERSION: EYELINK II 1\n",
      "4                                ** SOURCE: EYELINK CL\n",
      "dtype: object\n",
      "\n",
      "MSG DataFrame:\n",
      "      time                                   text\n",
      "0  2356867            !MODE RECORD CR 1000 2 0 LR\n",
      "1  2400101                    beginning_of_target\n",
      "2  2400107                  RECCFG CR 1000 2 0 LR\n",
      "3  2400107                        ELCLCFG BTABLER\n",
      "4  2400107  GAZE_COORDS 0.00 0.00 1920.00 1080.00\n",
      "\n",
      "Calibration DataFrame:\n",
      "                                                   0\n",
      "0  ** CONVERTED FROM ab01_second_half_2023-10-09_...\n",
      "1                  ** DATE: Sun Jun 29 00:37:35 2003\n",
      "2       ** TYPE: EDF_FILE BINARY EVENT SAMPLE TAGGED\n",
      "3                           ** VERSION: EYELINK II 1\n",
      "4                              ** SOURCE: EYELINK CL\n",
      "\n",
      "EyeLink Events DataFrame:\n",
      "\n",
      "Fix DataFrame:\n",
      "  eye   tStart     tEnd  duration   xAvg   yAvg  pupilAvg\n",
      "0   R  2356874  2356955        82  851.1  421.8       544\n",
      "1   L  2356874  2356960        87  869.6  428.5       579\n",
      "2   R  2357091  2357342       252  857.3  414.8       577\n",
      "3   L  2357074  2357347       274  880.5  392.2       609\n",
      "4   L  2357515  2357695       181  860.7  396.0       640\n",
      "\n",
      "Sacc DataFrame:\n",
      "  eye   tStart     tEnd  duration xStart yStart   xEnd   yEnd  ampDeg  vPeak\n",
      "0   L  2356961  2357073       113  869.2  438.1  882.0  340.3    1.55    472\n",
      "1   R  2356956  2357090       135  844.9  432.0  860.7  369.8    1.01    501\n",
      "2   L  2357348  2357514       167  884.4  401.2  864.2  320.0    1.31    357\n",
      "3   R  2357343  2357530       188  850.4  413.6  851.2  348.2    1.03    480\n",
      "4   R  2357696  2357719        24  844.4  435.3  925.2  498.5    1.61    148\n",
      "\n",
      "Blink DataFrame:\n",
      "  eye   tStart     tEnd  duration\n",
      "0   L  2356992  2357027        36\n",
      "1   R  2356989  2357036        48\n",
      "2   L  2357367  2357471       105\n",
      "3   R  2357364  2357481       118\n",
      "4   R  2368148  2368149         2\n",
      "\n",
      "Raw Sample Data DataFrame:\n",
      "   tSample     LX     LY  LPupil     RX     RY  RPupil\n",
      "0  2356867  863.5  427.5   577.0  851.3  424.3   542.0\n",
      "1  2356868  863.6  427.6   577.0  851.9  424.2   542.0\n",
      "2  2356869  863.8  427.9   576.0  852.7  424.4   543.0\n",
      "3  2356870  863.9  428.2   576.0  853.7  424.4   543.0\n",
      "4  2356871  863.9  428.4   576.0  854.0  424.5   543.0\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "edf_file_path = \"/home/gonzalo/Escritorio/edf_nuevo_dataset/ab01_second_half_2023-10-09_10h50.06.034.asc\"\n",
    "msg_keywords = []\n",
    "header_df, msg_df, calib_df, raw_sample_df, dict_events = parse_edf_eyelink(edf_file_path, msg_keywords)\n",
    "\n",
    "# Print the first few rows of each DataFrame\n",
    "print(\"Header DataFrame:\")\n",
    "print(header_df.head())\n",
    "print(\"\\nMSG DataFrame:\")\n",
    "print(msg_df.head())\n",
    "print(\"\\nCalibration DataFrame:\")\n",
    "print(calib_df.head())\n",
    "print(\"\\nEyeLink Events DataFrames:\")\n",
    "for event_type, df in dict_events.items():\n",
    "    print(f\"\\n{event_type.capitalize()} DataFrame:\")\n",
    "    print(df.head())\n",
    "print(\"\\nRaw Sample Data DataFrame:\")\n",
    "print(raw_sample_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
