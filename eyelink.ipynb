{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_besteye(df_msg, default='R'):\n",
    "    val_msgs = (df_msg[df_msg['text'].str.contains('CAL VALIDATION')][-2:]).to_numpy(dtype=str)\n",
    "    if not len(val_msgs) or 'ABORTED' in val_msgs[0][1]:\n",
    "        return default\n",
    "\n",
    "    left_index = int('LEFT' in val_msgs[1][1])\n",
    "    right_index = 1 - left_index\n",
    "    lefterror_index, righterror_index = val_msgs[left_index][1].split().index('ERROR'), val_msgs[right_index][\n",
    "        1].split().index('ERROR')\n",
    "    left_error = float(val_msgs[left_index][1].split()[lefterror_index + 1])\n",
    "    right_error = float(val_msgs[right_index][1].split()[righterror_index + 1])\n",
    "\n",
    "    return 'L' if left_error < right_error else 'R'\n",
    "\n",
    "\n",
    "def filter_msgs(df_msg, cutout='validation'):\n",
    "    first_index = df_msg.index[df_msg['text'].str.contains(cutout)].tolist()[0]\n",
    "\n",
    "    return df_msg[first_index:]\n",
    "\n",
    "\n",
    "def is_binocular(df_fix):\n",
    "    return len(df_fix['eye'].unique()) > 1\n",
    "\n",
    "\n",
    "def keep_besteye(df_fix, df_msg, default='R'):\n",
    "    best_eye = default\n",
    "    if is_binocular(df_fix):\n",
    "        best_eye = find_besteye(df_msg, default)\n",
    "        df_fix = df_fix[df_fix['eye'] == best_eye]\n",
    "\n",
    "    return df_fix, best_eye\n",
    "\n",
    "\n",
    "def extract_calpoints(df_msg, best_eye, legend='Calibration points', npoints=9):\n",
    "    calpoints_msg = df_msg[df_msg['text'].str.contains(legend)]\n",
    "    calpoints = []\n",
    "    if not calpoints_msg.empty:\n",
    "        if len(calpoints_msg) >= 2:\n",
    "            calpoints_msgidx = calpoints_msg.iloc[-2].name if best_eye == 'L' else calpoints_msg.iloc[-1].name\n",
    "        else:\n",
    "            calpoints_msgidx = calpoints_msg.iloc[0].name\n",
    "        calpoints = df_msg.loc[calpoints_msgidx + 1:calpoints_msgidx + npoints]['text'].to_numpy()\n",
    "        calpoints = [list(map(lambda x: float(x.replace(',', '')), msg.split()[1:3])) for msg in calpoints]\n",
    "    calpoints = pd.DataFrame(calpoints, columns=['x', 'y'])\n",
    "\n",
    "    return calpoints\n",
    "\n",
    "\n",
    "def extract_valpoints(df_msg, best_eye, legend='VALIDATE', npoints=9):\n",
    "    valpoints_msg = df_msg[df_msg['text'].str.contains(legend)]\n",
    "    if len(valpoints_msg) > npoints:\n",
    "        besteye_legend = 'RIGHT' if best_eye == 'R' else 'LEFT'\n",
    "        valpoints_msg = valpoints_msg[valpoints_msg['text'].str.contains(besteye_legend)]\n",
    "    valpoints_msg = valpoints_msg['text'].to_numpy()\n",
    "    points = [msg.split('at')[1].split('OFFSET')[0].split(',') for msg in valpoints_msg]\n",
    "    regexp = r'(-?\\d+\\.\\d+)\\s*,\\s*(-?\\d+\\.\\d+)\\s*pix'\n",
    "    offsets = [re.findall(regexp, msg.split('at')[1].split('OFFSET')[1]) for msg in valpoints_msg]\n",
    "    offsets = [(float(offset[0][0]), float(offset[0][1])) for offset in offsets]\n",
    "    points = [(int(point[0]), int(point[1])) for point in points]\n",
    "    valpoints = pd.DataFrame(points, columns=['x', 'y']).astype(int)\n",
    "    valoffsets = pd.DataFrame(offsets, columns=['x', 'y']).astype(float)\n",
    "\n",
    "    return valpoints, valoffsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_bids(folder_path, dataset_name, session_substrings=2):\n",
    "    \"\"\"\n",
    "    Convert a dataset to BIDS format.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing the dataset.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # List all files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    # Create a new folder for the BIDS dataset\n",
    "    bids_folder_path = os.path.join(folder_path, dataset_name)\n",
    "    os.makedirs(bids_folder_path, exist_ok=True)\n",
    "\n",
    "    # Create subfolders for each subject\n",
    "    subject_folders = []\n",
    "    for file in files:\n",
    "        if file.lower().endswith(\".edf\"):\n",
    "            subject_id = file.split(\"_\")[0]\n",
    "            subject_folder_path = os.path.join(bids_folder_path, \"sub-\" + subject_id)\n",
    "            os.makedirs(subject_folder_path, exist_ok=True)\n",
    "            subject_folders.append(subject_folder_path)\n",
    "\n",
    "    # Create subfolders for each session for each subject\n",
    "    for subject_folder in subject_folders:\n",
    "        for file in files:\n",
    "            if file.endswith(\".edf\") and file.startswith(os.path.basename(subject_folder)):\n",
    "                session_id = \"_\".join(file.split(\"_\")[1:session_substrings])\n",
    "                move_file_to_bids_folder(os.path.join(folder_path, file), bids_folder_path, subject_id, session_id, 'ET')\n",
    "            if file.endswith(\".bdf\") and file.startswith(os.path.basename(subject_folder)):\n",
    "                session_id = \"_\".join(file.split(\"_\")[1:session_substrings])\n",
    "                move_file_to_bids_folder(os.path.join(folder_path, file), bids_folder_path, subject_id, session_id, 'EEG')\n",
    "            if (file.endswith(\".log\") or file.endswith(\".csv\")) and file.startswith(os.path.basename(subject_folder)):\n",
    "                session_id = \"_\".join(file.split(\"_\")[1:session_substrings])\n",
    "                move_file_to_bids_folder(os.path.join(folder_path, file), bids_folder_path, subject_id, session_id, 'Psycopy')\n",
    "    return bids_folder_path\n",
    "\n",
    "def move_file_to_bids_folder(file_path, bids_folder_path, subject_id, session_id,tag):\n",
    "    session_folder_path = os.path.join(bids_folder_path, \"sub-\" + subject_id, \"ses-\" + session_id,tag)\n",
    "    os.makedirs(session_folder_path, exist_ok=True)\n",
    "    shutil.move(file_path, session_folder_path)\n",
    "    \n",
    "\n",
    "def convert_edf_to_ascii(edf_file_path, output_dir):\n",
    "    \"\"\"\n",
    "    Convert an EDF file to ASCII format using edf2asc.\n",
    "\n",
    "    Args:\n",
    "        edf_file_path (str): Path to the input EDF file.\n",
    "        output_dir (str): Directory to save the ASCII file. If None, the ASCII file will be saved in the same directory as the input EDF file.\n",
    "\n",
    "    Returns:\n",
    "        str: Path to the generated ASCII file.\n",
    "    \"\"\"\n",
    "    # Check if edf2asc is installed\n",
    "    if not shutil.which(\"edf2asc\"):\n",
    "        raise FileNotFoundError(\"edf2asc not found. Please make sure EyeLink software is installed and accessible in the system PATH.\")\n",
    "\n",
    "    # Set output directory\n",
    "    if output_dir is None:\n",
    "        raise ValueError(\"Output directory must be specified.\")\n",
    "\n",
    "    # Generate output file path\n",
    "    edf_file_name = os.path.basename(edf_file_path)\n",
    "    ascii_file_name = os.path.splitext(edf_file_name)[0] + \".asc\"\n",
    "    ascii_file_path = os.path.join(output_dir, ascii_file_name)\n",
    "\n",
    "    # Run edf2asc command with the -f flag, only run it if the file does not already exist\n",
    "    if not os.path.exists(ascii_file_path):\n",
    "        subprocess.run([\"edf2asc\", \"-f\", edf_file_path, ascii_file_path])\n",
    "\n",
    "    return ascii_file_path\n",
    "\n",
    "\n",
    "\n",
    "def parse_edf_eyelink(edf_file_path, msg_keywords,derivatives_folder,keep_ascii=True):\n",
    "    \"\"\"\n",
    "    Parse an EDF file generated by EyeLink system.\n",
    "\n",
    "    Args:\n",
    "        edf_file_path (str): Path to the input EDF file.\n",
    "        msg_keywords (list of str): List of strings representing keywords to filter MSG lines.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing five pandas DataFrames:\n",
    "            - Header information DataFrame\n",
    "            - MSG lines DataFrame filtered by msg_keywords\n",
    "            - Calibration information DataFrame\n",
    "            - EyeLink events DataFrame\n",
    "            - Raw sample data DataFrame\n",
    "    \"\"\"\n",
    "    # Convert EDF to ASCII\n",
    "    ascii_file_path = convert_edf_to_ascii(edf_file_path,derivatives_folder)\n",
    "\n",
    "    # ===== READ IN FILES ===== #\n",
    "    # Read in EyeLink file\n",
    "    \n",
    "    f = open(ascii_file_path,'r')\n",
    "    fileTxt0 = f.read().splitlines(True) # split into lines\n",
    "    fileTxt0 = np.array(fileTxt0) # concert to np array for simpler indexing\n",
    "    f.close()\n",
    "\n",
    "\n",
    "    # Separate lines into samples and messages\n",
    "    print('Sorting lines...')\n",
    "    nLines = len(fileTxt0)\n",
    "    lineType = np.array(['OTHER']*nLines,dtype='object')\n",
    "\n",
    "\n",
    "    # Usar lo de mne, particularmente para calibration.\n",
    "    # En sample tendría que filtrar lo que viene después de START y antes de END.\n",
    "    \n",
    "\n",
    "    calibration_flag = False\n",
    "    start_flag = False\n",
    "    for iLine in range(nLines):\n",
    "        if len(fileTxt0[iLine])<2:\n",
    "            lineType[iLine] = 'EMPTY'\n",
    "        elif fileTxt0[iLine].startswith('*'):\n",
    "            lineType[iLine] = 'HEADER'\n",
    "        # If there is a !CAL in the line, it is a calibration line\n",
    "        elif '!CAL' in fileTxt0[iLine]:\n",
    "            lineType[iLine] = 'Calibration'\n",
    "            calibration_flag = True\n",
    "        elif fileTxt0[iLine].split()[0] == 'START' and calibration_flag:\n",
    "            calibration_flag = False\n",
    "            start_flag = True\n",
    "        elif calibration_flag:\n",
    "            lineType[iLine] = 'Calibration'\n",
    "        elif not start_flag: # Data before the first successful calibration is discarded. \n",
    "            # After the first successul calibration, EVERY sample is taken into account.\n",
    "            lineType[iLine] = 'Non_calibrated_samples'\n",
    "        elif fileTxt0[iLine].split()[0] == 'MSG' and any(keyword in fileTxt0[iLine] for keyword in msg_keywords):\n",
    "            lineType[iLine] = 'MSG'\n",
    "        elif fileTxt0[iLine].split()[0] == 'ESACC':\n",
    "            lineType[iLine] = 'ESACC'\n",
    "        elif fileTxt0[iLine].split()[0] == 'EFIX':\n",
    "            lineType[iLine] = 'EFIX'\n",
    "        elif fileTxt0[iLine].split()[0] == 'EBLINK':\n",
    "            lineType[iLine] = 'EBLINK'\n",
    "        elif fileTxt0[iLine].split()[0][0].isdigit() or fileTxt0[iLine].split()[0].startswith('-'):\n",
    "            lineType[iLine] = 'SAMPLE'\n",
    "        else:\n",
    "            lineType[iLine] = 'OTHER'\n",
    "        \n",
    " \n",
    "    # ===== PARSE EYELINK FILE ===== #\n",
    "    # Import Header\n",
    "    print('Parsing header...')\n",
    "    dfHeader = pd.read_csv(ascii_file_path,skiprows=np.nonzero(lineType!='HEADER')[0],header=None,sep='\\s+')\n",
    "    # Merge columns into single strings\n",
    "    dfHeader = dfHeader.apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1)\n",
    "\n",
    "\n",
    "    # Import Calibration\n",
    "    print('Parsing calibration...')\n",
    "    iCal = np.nonzero(lineType!='Calibration')[0]\n",
    "    dfCalib = pd.read_csv(ascii_file_path,skiprows=iCal,names=np.arange(9))\n",
    "\n",
    "\n",
    "\n",
    "    # Import Message\n",
    "    print('Parsing messages...')\n",
    "    i_msg = np.nonzero(lineType == 'MSG')[0]\n",
    "    t_msg = []\n",
    "    txt_msg = []\n",
    "    for i in range(len(i_msg)):\n",
    "        # separate MSG prefix and timestamp from rest of message\n",
    "        info = fileTxt0[i_msg[i]].split()\n",
    "        # extract info\n",
    "        t_msg.append(int(info[1]))\n",
    "        txt_msg.append(' '.join(info[2:]))\n",
    "    dfMsg = pd.DataFrame({'time': t_msg, 'text': txt_msg})\n",
    "\n",
    "    # Import Fixations\n",
    "    print('Parsing fixations...')\n",
    "    i_not_efix = np.nonzero(lineType != 'EFIX')[0]\n",
    "    df_fix = pd.read_csv(ascii_file_path, skiprows=i_not_efix, header=None, sep='\\s+', usecols=range(1, 8),\n",
    "                         low_memory=False)\n",
    "    df_fix.columns = ['eye', 'tStart', 'tEnd', 'duration', 'xAvg', 'yAvg', 'pupilAvg']\n",
    "\n",
    "    # Saccades\n",
    "    print('Parsing saccades...')\n",
    "    i_not_esacc = np.nonzero(lineType != 'ESACC')[0]\n",
    "    df_sacc = pd.read_csv(ascii_file_path, skiprows=i_not_esacc, header=None, sep='\\s+', usecols=range(1, 11),\n",
    "                          low_memory=False)\n",
    "    df_sacc.columns = ['eye', 'tStart', 'tEnd', 'duration', 'xStart', 'yStart', 'xEnd', 'yEnd', 'ampDeg', 'vPeak']\n",
    "\n",
    "    # Blinks\n",
    "    print('Parsing blinks...')\n",
    "    df_blink = pd.DataFrame()\n",
    "    i_not_eblink = np.nonzero(lineType != 'EBLINK')[0]\n",
    "    if len(i_not_eblink) < nLines:\n",
    "        df_blink = pd.read_csv(ascii_file_path, skiprows=i_not_eblink, header=None, sep='\\s+', usecols=range(1, 5),\n",
    "                               low_memory=False)\n",
    "        df_blink.columns = ['eye', 'tStart', 'tEnd', 'duration']\n",
    "\n",
    "    # determine sample columns based on eyes recorded in file\n",
    "    eyes_in_file = np.unique(df_fix.eye)\n",
    "    if eyes_in_file.size == 2:\n",
    "        cols = ['tSample', 'LX', 'LY', 'LPupil', 'RX', 'RY', 'RPupil']\n",
    "    else:\n",
    "        eye = eyes_in_file[0]\n",
    "        print('monocular data detected (%c eye).' % eye)\n",
    "        cols = ['tSample', '%cX' % eye, '%cY' % eye, '%cPupil' % eye]\n",
    "\n",
    "    # Import samples\n",
    "    i_not_sample = np.nonzero(lineType != 'SAMPLE')[0]\n",
    "    dfSamples = pd.read_csv(ascii_file_path, skiprows=i_not_sample, header=None, sep='\\s+',\n",
    "                                usecols=range(0, len(cols)), low_memory=False)\n",
    "    dfSamples.columns = cols\n",
    "    # Convert values to numbers\n",
    "    for eye in ['L', 'R']:\n",
    "        if eye in eyes_in_file:\n",
    "            dfSamples['%cX' % eye] = pd.to_numeric(dfSamples['%cX' % eye], errors='coerce')\n",
    "            dfSamples['%cY' % eye] = pd.to_numeric(dfSamples['%cY' % eye], errors='coerce')\n",
    "            dfSamples['%cPupil' % eye] = pd.to_numeric(dfSamples['%cPupil' % eye], errors='coerce')\n",
    "        else:\n",
    "            dfSamples['%cX' % eye] = np.nan\n",
    "            dfSamples['%cY' % eye] = np.nan\n",
    "            dfSamples['%cPupil' % eye] = np.nan\n",
    "\n",
    "    dict_events = {'fix': df_fix, 'sacc': df_sacc, 'blink': df_blink}\n",
    "    if not keep_ascii:\n",
    "        os.remove(ascii_file_path)\n",
    "\n",
    "    # Save the 5 data structures in HDF5 file each, in the derivatives folder\n",
    "    dfHeader.to_hdf(os.path.join(derivatives_folder, 'header.hdf5'), key='dfHeader', mode='w')\n",
    "    dfMsg.to_hdf(os.path.join(derivatives_folder, 'msg.hdf5'), key='dfMsg', mode='w')\n",
    "    dfCalib.to_hdf(os.path.join(derivatives_folder, 'calib.hdf5'), key='dfCalib', mode='w')\n",
    "    dfSamples.to_hdf(os.path.join(derivatives_folder, 'samples.hdf5'), key='dfSamples', mode='w')\n",
    "    for key, value in dict_events.items():\n",
    "        value.to_hdf(os.path.join(derivatives_folder, key + '.hdf5'), key=key, mode='w')\n",
    "\n",
    "\n",
    "def compute_derivatives_for_dataset(bids_dataset_folder, msg_keywords):\n",
    "    \"\"\"\n",
    "    Compute derivatives for a dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset_folder (str): Path to the folder containing the dataset.\n",
    "        msg_keywords (list of str): List of strings representing keywords to filter MSG lines. Leave empty if no\n",
    "            filtering is required.\n",
    "        derivatives_folder (str): Path to the folder to save the derivatives.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    derivatives_folder = bids_dataset_folder + \"_derivatives\"\n",
    "    # Create the derivatives folder\n",
    "    os.makedirs(derivatives_folder, exist_ok=True)\n",
    "\n",
    "    # List of folders in bids_dataset_folder\n",
    "    bids_folders = os.listdir(bids_dataset_folder)\n",
    "    # Filter out non-subject folders\n",
    "    bids_folders = [folder for folder in bids_folders if folder.startswith(\"sub-\")]\n",
    "\n",
    "    # Compute derivatives for each EDF file in the dataset\n",
    "    for subject in bids_folders:\n",
    "        # List of folders in subject folder\n",
    "        sessions_folders = os.listdir(os.path.join(bids_dataset_folder, subject))\n",
    "        # Filter out non-session folders\n",
    "        sessions_folders = [folder for folder in sessions_folders if folder.startswith(\"ses-\")]\n",
    "        for session in os.listdir(os.path.join(bids_dataset_folder, subject)):\n",
    "            for file in os.listdir(os.path.join(bids_dataset_folder, subject, session,'ET')):\n",
    "                if file.lower().endswith(\".edf\"):\n",
    "                    edf_file_path = os.path.join(bids_dataset_folder, subject, session, file)\n",
    "                    derivatives_folder_path = os.path.join(derivatives_folder, subject, session)\n",
    "                    os.makedirs(derivatives_folder_path, exist_ok=True)\n",
    "                    parse_edf_eyelink(edf_file_path, msg_keywords, derivatives_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting lines...\n",
      "Parsing header...\n",
      "Parsing calibration...\n",
      "Parsing messages...\n",
      "Parsing fixations...\n",
      "Parsing saccades...\n",
      "Parsing blinks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7757/3381608640.py:233: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->Index([0, 1, 2, 3], dtype='int64')]\n",
      "\n",
      "  dfCalib.to_hdf(os.path.join(derivatives_folder, 'calib.hdf5'), key='dfCalib', mode='w')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting lines...\n",
      "Parsing header...\n",
      "Parsing calibration...\n",
      "Parsing messages...\n",
      "Parsing fixations...\n",
      "Parsing saccades...\n",
      "Parsing blinks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7757/3381608640.py:233: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->Index([0, 1, 2, 3], dtype='int64')]\n",
      "\n",
      "  dfCalib.to_hdf(os.path.join(derivatives_folder, 'calib.hdf5'), key='dfCalib', mode='w')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting lines...\n",
      "Parsing header...\n",
      "Parsing calibration...\n",
      "Parsing messages...\n",
      "Parsing fixations...\n",
      "Parsing saccades...\n",
      "Parsing blinks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7757/3381608640.py:233: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->Index([0, 1, 2, 3], dtype='int64')]\n",
      "\n",
      "  dfCalib.to_hdf(os.path.join(derivatives_folder, 'calib.hdf5'), key='dfCalib', mode='w')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting lines...\n",
      "Parsing header...\n",
      "Parsing calibration...\n",
      "Parsing messages...\n",
      "Parsing fixations...\n",
      "Parsing saccades...\n",
      "Parsing blinks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7757/3381608640.py:233: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->Index([0, 1, 2, 3], dtype='int64')]\n",
      "\n",
      "  dfCalib.to_hdf(os.path.join(derivatives_folder, 'calib.hdf5'), key='dfCalib', mode='w')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting lines...\n",
      "Parsing header...\n",
      "Parsing calibration...\n",
      "Parsing messages...\n",
      "Parsing fixations...\n",
      "Parsing saccades...\n",
      "Parsing blinks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7757/3381608640.py:233: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->Index([0, 1, 2, 3], dtype='int64')]\n",
      "\n",
      "  dfCalib.to_hdf(os.path.join(derivatives_folder, 'calib.hdf5'), key='dfCalib', mode='w')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting lines...\n",
      "Parsing header...\n",
      "Parsing calibration...\n",
      "Parsing messages...\n",
      "Parsing fixations...\n",
      "Parsing saccades...\n",
      "Parsing blinks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7757/3381608640.py:233: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->Index([0, 1, 2, 3], dtype='int64')]\n",
      "\n",
      "  dfCalib.to_hdf(os.path.join(derivatives_folder, 'calib.hdf5'), key='dfCalib', mode='w')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting lines...\n",
      "Parsing header...\n",
      "Parsing calibration...\n",
      "Parsing messages...\n",
      "Parsing fixations...\n",
      "Parsing saccades...\n",
      "Parsing blinks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7757/3381608640.py:233: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->Index([0, 1, 2, 3], dtype='int64')]\n",
      "\n",
      "  dfCalib.to_hdf(os.path.join(derivatives_folder, 'calib.hdf5'), key='dfCalib', mode='w')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting lines...\n",
      "Parsing header...\n",
      "Parsing calibration...\n",
      "Parsing messages...\n",
      "Parsing fixations...\n",
      "Parsing saccades...\n",
      "Parsing blinks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7757/3381608640.py:233: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->Index([0, 1, 2, 3], dtype='int64')]\n",
      "\n",
      "  dfCalib.to_hdf(os.path.join(derivatives_folder, 'calib.hdf5'), key='dfCalib', mode='w')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting lines...\n",
      "Parsing header...\n",
      "Parsing calibration...\n",
      "Parsing messages...\n",
      "Parsing fixations...\n",
      "Parsing saccades...\n",
      "Parsing blinks...\n",
      "monocular data detected (L eye).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7757/3381608640.py:233: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->Index([0, 1, 2, 3], dtype='int64')]\n",
      "\n",
      "  dfCalib.to_hdf(os.path.join(derivatives_folder, 'calib.hdf5'), key='dfCalib', mode='w')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting lines...\n",
      "Parsing header...\n",
      "Parsing calibration...\n",
      "Parsing messages...\n",
      "Parsing fixations...\n",
      "Parsing saccades...\n",
      "Parsing blinks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7757/3381608640.py:233: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->Index([0, 1, 2, 3], dtype='int64')]\n",
      "\n",
      "  dfCalib.to_hdf(os.path.join(derivatives_folder, 'calib.hdf5'), key='dfCalib', mode='w')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting lines...\n",
      "Parsing header...\n",
      "Parsing calibration...\n",
      "Parsing messages...\n",
      "Parsing fixations...\n",
      "Parsing saccades...\n",
      "Parsing blinks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7757/3381608640.py:233: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->Index([0, 1, 2, 3], dtype='int64')]\n",
      "\n",
      "  dfCalib.to_hdf(os.path.join(derivatives_folder, 'calib.hdf5'), key='dfCalib', mode='w')\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "current_folder = os.getcwd()\n",
    "bids_dataset_folder = dataset_to_bids(current_folder, \"example_dataset\")\n",
    "msg_keywords = [\"begin\",\"end\",\"press\"]\n",
    "compute_derivatives_for_dataset(bids_dataset_folder, msg_keywords)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
